[[["3b0ce112-bd04-4652-a28f-719cd34ee07d",{"pageContent":"RajuN\nPhone:860-248-9503\n♦\nnune2642@gmail.com\nSeniorDataAnalyst\nExpertiseinDataWarehousingandBigDatadevelopmentlifecycle\nSummary:Over12+yearsofITexperienceinAnalysis,design,testingandImplementationofBusiness\nIntelligencesolutionsusingDataWarehouse/DataMartDesign,ETL,OLAP,Client/Serverapplications.\nExperiencedinallphasesofrequirementsinend-to-endtasksindifferentSDLCAGILE,IterativeandWaterfall\nforprojecttestingmethodologies.\nTenPlus(12+)Yearsofhands-onexperienceinOracleandPL/SQLwritingStoredProcedures,,triggers,\nviews,materializedviews.\nNinePlus(10+)GoodunderstandingofDataWarehouse/Datamartconcepts,OLAP&OLTPsystemsfrom\ndesignandanalysistoimplementation.\nNinePlus(10+)yearsofexperienceinDataAcquisition,MasterDataManagement,DataAnalysis,Business\nIntelligence&DataArchitecture.\nNinePlus(10+)Yearsofexperienceindatawarehousingapplicationsincludinganalysis,architecture,design,\ndevelopment&supportusingInformaticaPowerCenter,Linux,Databricks,Python.","metadata":{"source":"/tmp/resume-processor-sLMqmq/Raju_DA.DOCX.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Copy of Raju_N_DA.DOCX","Producer":"Skia/PDF m122 Google Docs Renderer"},"metadata":null,"totalPages":8},"loc":{"pageNumber":1,"lines":{"from":1,"to":18}}}}],["dc59d854-b285-480d-b844-ab81d6c1ee8d",{"pageContent":"NinePlus(10+)Yearsofexperienceindatawarehousingapplicationsincludinganalysis,architecture,design,\ndevelopment&supportusingInformaticaPowerCenter,Linux,Databricks,Python.\nExtensiveexperienceondevelopingETLcodeinInformaticaPowerCenterusingcomponentssuchas\nPowerCenterDesigner,PowerCenterRepositoryManager,WorkflowManagerandmonitoringand\ntroubleshootingusingWorkflowMonitor.IBMDataStage9/8.1,SSIS.\nLeverageabroadstackoftechnologies—Python,Docker,AWS,Airflow,andSparktorevealtheinsights\nhiddenwithinhugevolumesofnumericandtextualdata\nSixPlus(6+)YearsofexperiencewithNoSQLdatabases(MongoDB,Cassandra)andHadoopbigdata\necosystem(HDFS,MapReduce,Hive,Spark,Impala,)\nExperience&Achievements\nOptum(UHG),MN(Remote.)February2023–TillDate\nSr.SystemAnalyst(ETL//BIGData/AWS)\nResponsibilities:\n▪DevelopedTestPlan,TestCases,Scenarios,TestData&TestStrategydocumentsbasedonBRD\nmappedtoTestScriptstoensureanyChangeControlinrequirementsleadstotestcaseupdate.","metadata":{"source":"/tmp/resume-processor-sLMqmq/Raju_DA.DOCX.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Copy of Raju_N_DA.DOCX","Producer":"Skia/PDF m122 Google Docs Renderer"},"metadata":null,"totalPages":8},"loc":{"pageNumber":1,"lines":{"from":17,"to":31}}}}],["01c00c14-ae7e-4036-a109-c751a1108626",{"pageContent":"Responsibilities:\n▪DevelopedTestPlan,TestCases,Scenarios,TestData&TestStrategydocumentsbasedonBRD\nmappedtoTestScriptstoensureanyChangeControlinrequirementsleadstotestcaseupdate.\n \n▪DevelopedcomplexSQLScriptstovalidatetheCompleteness,Correctness,IntegrityandAccuracy\nofDataloadedintotargetdatabaseaccordingtotheBRDwithinanETLprocesstestingcycle.\n \n▪CompleteresponsibleforQAdeliverablesthatincludesCode/Datamigrationandmaintainingallthe\ntestcasesanddefectsinHPQCALMforalltheprojectsfromQAstand-point.\n \n▪Responsibleforanalyzingnewdatasources(KaRka,RDBMS,logetc.)andbringindataintotarget\nsysteminnearreal-time.\n \n▪AnalyzeandcleanserawdatausingHiveQL\n \n▪ExperienceindatatransformationsusingMap-Reduce,andHIVEfordifferentRileformats.\n \n▪InvolvedinconvertingHive/SQLqueriesintotransformationsusingPython.\n \n▪Performedcomplexjoinsontablesinahivewithvariousoptimizationtechniques\n \n▪CreatedHivetablesasperrequirements,internalorexternaltablesdeRinedwithappropriatestatic\nand","metadata":{"source":"/tmp/resume-processor-sLMqmq/Raju_DA.DOCX.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Copy of Raju_N_DA.DOCX","Producer":"Skia/PDF m122 Google Docs Renderer"},"metadata":null,"totalPages":8},"loc":{"pageNumber":1,"lines":{"from":29,"to":51}}}}],["97701e15-7684-4077-a50a-8ab01f2c1b30",{"pageContent":"▪Performedcomplexjoinsontablesinahivewithvariousoptimizationtechniques\n \n▪CreatedHivetablesasperrequirements,internalorexternaltablesdeRinedwithappropriatestatic\nand\ndynamicpartitions,intendedforefRiciency.\n \n▪WorkedonBuildingpartoforacledatabaseinRedshift.","metadata":{"source":"/tmp/resume-processor-sLMqmq/Raju_DA.DOCX.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Copy of Raju_N_DA.DOCX","Producer":"Skia/PDF m122 Google Docs Renderer"},"metadata":null,"totalPages":8},"loc":{"pageNumber":1,"lines":{"from":48,"to":54}}}}],["99c82890-ffd0-4bd7-b0ad-d64635ed51f9",{"pageContent":"▪WroteLinux/DatabricksforimportingandexportingdatafromRDBMStoHDFS.\n \n▪WorkedextensivelywithHIVEDDLSandHiveQuerylanguage(HQL)\n \n▪InvolvedinloadingdatafromtheedgenodetoHDFSusingshellscripting.\n \n▪Hands-onexperienceonworkingwithAWSserviceslikeLambdafunction,Athena,DynamoDB,Step\nfunctions,SNS,\n \n▪SQS,S3,IAMetc.\n \n▪ExperienceinbuildingpowerbireportsonAzureAnalysisservicesforbetterperformancewhen\ncomparingthatto\n \n▪CreatedandmaintainedtechnicaldocumentationforlaunchingtheHadoopclusterandforexecuting\nHivequeries.\n \n▪BuildIntegrationbetweenapplicationsprimarilySalesforce.\n \n▪conRigurations,Real-Timeappslikeprocessdesignerandprocessdeveloper.\n \n▪CarriedoutdatatransformationandcleansingusingSQLqueriesandPySpark.\n \n▪WorkextensivelywithRlatRiles.Loadingthemintoon-premiseapplicationsandretrievingdatafrom\napplicationstoRiles.\n \n▪WriteSQLqueriesandcreatetestdatainsalesforceforDatabrickscloudmappingsunittesting.\n \n▪PrepareTDDs,TestCasedocumentsaftereachprocesshasbeendeveloped.","metadata":{"source":"/tmp/resume-processor-sLMqmq/Raju_DA.DOCX.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Copy of Raju_N_DA.DOCX","Producer":"Skia/PDF m122 Google Docs Renderer"},"metadata":null,"totalPages":8},"loc":{"pageNumber":2,"lines":{"from":2,"to":30}}}}],["9fd73a74-a455-481c-a811-59d98ae87979",{"pageContent":"applicationstoRiles.\n \n▪WriteSQLqueriesandcreatetestdatainsalesforceforDatabrickscloudmappingsunittesting.\n \n▪PrepareTDDs,TestCasedocumentsaftereachprocesshasbeendeveloped.\n \n▪Identifyandvalidatedatabetweensourceandtargetapplications.\n \n▪Verifydataconsistencybetweensystems.\n \n▪Wasresponsibleforcreatingon-demandtablesonS3RilesusingLambdaFunctionsandAWSGlue\nusing\nPythonandSpark.\n \n▪CoordinatedwiththeteamandDevelopedaframeworktogenerateDailyadhoc,reports,and\nextracts\nfromenterprisedataandautomatedusingDatabricksJobScheduler.\n \n▪DesignedandCo-ordinatedwiththeDataScienceteaminimplementingAdvancedAnalyticalModels\nin\nHadoopClusteroverlargeDatasets.\n \n▪Createdmonitors,alarms,notiRicationsandlogsforLambdafunctions,GlueJobs,andEC2hosts\nusing\nCloudwatch\n \n▪UsedAWSGlueforthedatatransformation,validationanddatacleansing.\n \n▪UsedPythonBoto3toconRiguretheservicesAWSglue,EC2,S3.\n \n▪Buildnear-real-timepipelinesbyconsumingdatafromKaRkaandtoloaddataintoAWSCloudData\nLake.","metadata":{"source":"/tmp/resume-processor-sLMqmq/Raju_DA.DOCX.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Copy of Raju_N_DA.DOCX","Producer":"Skia/PDF m122 Google Docs Renderer"},"metadata":null,"totalPages":8},"loc":{"pageNumber":2,"lines":{"from":26,"to":57}}}}],["cf208e91-6ee5-43ff-abbc-0fdda8af96d6",{"pageContent":"▪UsedPythonBoto3toconRiguretheservicesAWSglue,EC2,S3.\n \n▪Buildnear-real-timepipelinesbyconsumingdatafromKaRkaandtoloaddataintoAWSCloudData\nLake.\n \n▪WorkingexperienceonJIRAtocommunicateProjectManagementalldefectsraisedduringtest\ncycles.\n \n▪WorkingexperienceonagilemodelanddailyScrumStand-upsforQAupdatesanddefectstatus.\n \n▪ExperiencedonDefectmanagementlifecycle&raisedthedefectsbasedonprioritylevelinHPALM\nEnvironment:HPALM,Jira,Azure,Databricks,Erwin,RDBMS,Hadoop,HDFS,Hive,PIG,Cloudera,\nMapReduce,Python,AWS,Unixscripts,FlatFiles,XMLRilesMachineLearning-Algorithms,KaRka,\nOffsetExplorer\nCMS/NPSS,Columbia,WAJuly2017–current\nSystemsDATAANALYST\nEnvironment:MDM,AWS-Cloud,EMR,Pyspark,DMExpress,Informatica,DB2,Linux,Unix,Shell,Scripting,\nPythonPandas,Databricks,Qubole,Jira,Data-Frames,HiveMetastore,Teradata14,PL/SQL,Eclipse,Java,\nDataStudio,JupyterAnaconda3,SoapUI,MicroStrategy,Mobaxterm,Winmerge,JMeter","metadata":{"source":"/tmp/resume-processor-sLMqmq/Raju_DA.DOCX.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Copy of Raju_N_DA.DOCX","Producer":"Skia/PDF m122 Google Docs Renderer"},"metadata":null,"totalPages":8},"loc":{"pageNumber":2,"lines":{"from":54,"to":72}}}}],["b08a2228-9aec-4847-b393-21fc7408a2c4",{"pageContent":"Kroger,Cincinnati,Ohio(October2015–Jun\n2017)\nNGLSr.DataAnalyst\n•DevelopedMapping’sinAginityManagementworkbenchforloadingdataintocorresponding\nsources\n•DevelopedAttributesinAttriubteworkbenchforloadingthedatausingMappingrules\n•PublishedusingPublicationwizardofAginityAmpthedatatotestthedataagainstTables\npresentinstaging\n•PerformedFunctionalTestingandBack-endTestingusingthedatabasecomparableresults.\n•Created,Loadnewormodifieddataintoback-endNetezzadatabase.\n•InvolvedindoubleprogrammingandQCcheckoftheprogramswrittenbyfellowprogrammers.\n•CreatedTables,GraphsandListingsforclinicalstudy.\n•ExtensivelyusedSQLprogramminginbackendandfront-endfunctions,procedures,packagesto\nimplementbusinessrulesandsecurity\n•CreatedIBMUnicaCampaignsflatfilesforprovidingtothevendorfortherecampaign\ngeneration\n•CreatedTivolijobs,JobStream&RanthemfororchestrationofdataloadsusingShellscript\n•DevelopedjsonfilethatcreatessqlfileswhichloadsdatabyusingthesqlgeneratedbyAginity\nAMP","metadata":{"source":"/tmp/resume-processor-sLMqmq/Raju_DA.DOCX.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Copy of Raju_N_DA.DOCX","Producer":"Skia/PDF m122 Google Docs Renderer"},"metadata":null,"totalPages":8},"loc":{"pageNumber":3,"lines":{"from":1,"to":19}}}}],["f9cfefd9-62c9-4e06-a785-c95e2b8310fb",{"pageContent":"generation\n•CreatedTivolijobs,JobStream&RanthemfororchestrationofdataloadsusingShellscript\n•DevelopedjsonfilethatcreatessqlfileswhichloadsdatabyusingthesqlgeneratedbyAginity\nAMP\n•DevelopedshellScripttoloadtextfilespresentinunixboxintocorrespondingdatabase\n•DevelopedCognosreportsaspertheOrganizationstandardsandtestedthem\n•DevelopedtableaureportstoensureavailabilityofCampaigningdatatomeettheNeedsofIBM\nUnicaCampaign\n•DevelopedshellscriptthatloadsintoNetezzatablespresentusingpublicationpresentinAginity\nAMP\n•Designed&CreatedMappingdocumentsbasedontheBusinessrequirements(Alsoreferred\nSourcetoTargetDetailedmappingdocument&Transformationrulesdocument).\n•InvolvedinthepreparationofTestStrategy&TestCases\n•DevelopedandPerformedexecutionofTestScriptstoshowhowmanyrecordsarepassedorfail\n•LoadeddataintonetezzatablesfromvariousdatasourceslikeNetezza,SQLServer,Oracle,flat\nfilesbycreatingInformaticaMappings\n•AssistedincreatingfactanddimensiontableimplementationinStarSchemamodelbasedon\nrequirements.","metadata":{"source":"/tmp/resume-processor-sLMqmq/Raju_DA.DOCX.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Copy of Raju_N_DA.DOCX","Producer":"Skia/PDF m122 Google Docs Renderer"},"metadata":null,"totalPages":8},"loc":{"pageNumber":3,"lines":{"from":16,"to":33}}}}],["6d563e6e-011e-4097-accc-1ca8b88f4522",{"pageContent":"filesbycreatingInformaticaMappings\n•AssistedincreatingfactanddimensiontableimplementationinStarSchemamodelbasedon\nrequirements.\n•CreatedETLtestdataforallETLmappingrulestotestthefunctionalitydata\n•WrotecomplexSQLscriptsusinginnerjoins,Crossjoinsandouterjoinsandsubqueries\n•CreateTestscriptsbyusingT-SQL.Programmingelementsincludecontrol-of-flowtechniques,\nlocalandglobalvariables,functions,anderrorhandlingtechniques\n•Participatedinthereleasecontrolprocess(whentheapplicationistransferredfromthebuildteam\ntothetestteam)toensurethatsolutionsmeetbusinessrequirements\n•ParticipatedinthePIPlanning:QuantitativeMetrics(togetanideaofthebusinessvaluegained\nduringPrviousPI)\n•SprintDemowithBussinessUsers(Ademotorevieweverythingcompletedduringthesprint)\n•ExtensivelyexecutedT-SQLqueriesinordertoviewsuccessfultransactionsofdataandfor\nvalidatingdatainSqlServerDatabase\n•ValidatingtheCognosreportingobjectsinthereporteragainstthedesignspecificationdocument.","metadata":{"source":"/tmp/resume-processor-sLMqmq/Raju_DA.DOCX.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Copy of Raju_N_DA.DOCX","Producer":"Skia/PDF m122 Google Docs Renderer"},"metadata":null,"totalPages":8},"loc":{"pageNumber":3,"lines":{"from":31,"to":45}}}}],["20f846cc-1730-4a59-9059-4ee431de0e87",{"pageContent":"validatingdatainSqlServerDatabase\n•ValidatingtheCognosreportingobjectsinthereporteragainstthedesignspecificationdocument.\n•StrongKnowledgeinprotocolslikeSSHandSCPandtestedtheapplicationinUnixEnvironment\n•TestedthedimensionalcubesdevelopedbySQLServerAnalysisServices(SSAS)andqueried\nthedatausingSQLServerManagementstudio(SSMS)\n•DidDataModelingtestingforsourceidentification,datacollection,datatransformation,rule\nadministration,dataconsolidationanddatareconciliation.\n•Developedsqltoidentifythedeltasofdailyloads","metadata":{"source":"/tmp/resume-processor-sLMqmq/Raju_DA.DOCX.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Copy of Raju_N_DA.DOCX","Producer":"Skia/PDF m122 Google Docs Renderer"},"metadata":null,"totalPages":8},"loc":{"pageNumber":3,"lines":{"from":44,"to":51}}}}],["eb078586-bbff-4c0d-b323-fb3d5585e57a",{"pageContent":"•IdentifyingfieldanddatadefectswithrequiredinformationinETLprocessinvariousmappings\nandonetoonemapping.\n•VerifiedalltheDataloadprocessesdevelopedforfetchingdatafromBigDatasystemtothe\nEnterpriseDatawarehouseusingSQLqueries.\n•PerformeddatavalidationontheflatfilesthatweregeneratedinUNIXandNetezzaenvironment\nusingUNIXandsqlLoadercommandsasnecessary\n•Defectsidentifiedintestingenvironmentwherecommunicatedtothedevelopersusingdefect\ntrackingtoolMercuryTest\n•Reportedthedefects/buginJiraticketsanddocumentedthereport.\n•Checkedthereportsforanynaminginconsistenciesandtoimproveuserreadability.\nEnvironment:AginityAmpPureAnalytics,NetezzaRelease7.2.1.1,Unix,Putty,Tivoli,Informatica,Confluence,Jira,\nAgile,IBMCognos10,IBMUnicaCampaign,HadoopHive,SqlServer,Oracle,Mobaxterm,Tableau\nIntuitTurbotax,Sandiego,CA(November2014–Sep2015)\nSr.BigDataAnalyst\n•Designed&CreatedMappingdocumentsbasedontheBusinessrequirements(Alsoreferred\nSourcetoTargetDetailedmappingdocument&Transformationrulesdocument).","metadata":{"source":"/tmp/resume-processor-sLMqmq/Raju_DA.DOCX.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Copy of Raju_N_DA.DOCX","Producer":"Skia/PDF m122 Google Docs Renderer"},"metadata":null,"totalPages":8},"loc":{"pageNumber":4,"lines":{"from":1,"to":16}}}}],["cb331347-3a9f-48ff-a90d-17db84837622",{"pageContent":"Sr.BigDataAnalyst\n•Designed&CreatedMappingdocumentsbasedontheBusinessrequirements(Alsoreferred\nSourcetoTargetDetailedmappingdocument&Transformationrulesdocument).\n•DevelopedapythonscripttogenerateTSVfilethatshowsnumberofcolumnsarenulland\nnumberofduplicaterecordsattablelevel\n•Developedpythonscriptstoexecutedatabasesqlqueriesandscheduledtheminjenkinsjobsto\nshow\nStatusoftestcase\n•Createdjenkinjobstorunscheduledpythonscriptsthathascomplexsqlqueriesfordata\nverification\n•DevelopedshellScripttoloadtextfilespresentinunixboxintocorrespondingdatabase\n•DevelopedtableaureportsaspertheOrganizationstandardsandtestedthem\n•Developedshellscriptincronjobtoreportdiskspaceusageofunixserver\n•DevelopedtableaureportstoensureavailabilityofdatainallthetableofverticatomeetUAT\nneeds\n•Developedshellscriptthatloadsintooracledatabasepresentinunixboxforreconcilingsource\ndata\n•Interactingwithseniorpeersorsubjectmatterexpertstolearnmoreabouttherequirements\n•InvolvedinthepreparationofTestStrategy&TestCases","metadata":{"source":"/tmp/resume-processor-sLMqmq/Raju_DA.DOCX.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Copy of Raju_N_DA.DOCX","Producer":"Skia/PDF m122 Google Docs Renderer"},"metadata":null,"totalPages":8},"loc":{"pageNumber":4,"lines":{"from":14,"to":32}}}}],["b61586eb-9851-46fa-bdff-2588301f50cc",{"pageContent":"data\n•Interactingwithseniorpeersorsubjectmatterexpertstolearnmoreabouttherequirements\n•InvolvedinthepreparationofTestStrategy&TestCases\n•ActivelyinvolvedinFunctionalTesting,RegressionTesting.\n•DevelopedandPerformedexecutionofTestScriptstoshowhowmanyrecordsarepassedorfail\n•TransformeddatafromvariousdatasourceslikeNetezza,DB2,Oracle,flatfilesusingOLEDB\nconnectionbycreatingvariousSSISpackages\n•CreatedETLtestdataforallETLmappingrulestotestthefunctionalitydata\n•DevelopedcomplexSQLscriptsusinginnerjoinsandouterjoinsandsubqueries\n•CreateTestscriptsbyusingT-SQL.Programmingelementsincludecontrol-of-flowtechniques,\nlocalandglobalvariables,functions,anderrorhandlingtechniques\n•Participatedinthereleasecontrolprocess(whentheapplicationistransferredfromthebuildteam\ntothetestteam)toensurethatsolutionsmeetbusinessrequirements\n•ExtensivelyexecutedT-SQLqueriesinordertoviewsuccessfultransactionsofdataandfor\nvalidatingdatainSqlServerDatabas","metadata":{"source":"/tmp/resume-processor-sLMqmq/Raju_DA.DOCX.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Copy of Raju_N_DA.DOCX","Producer":"Skia/PDF m122 Google Docs Renderer"},"metadata":null,"totalPages":8},"loc":{"pageNumber":4,"lines":{"from":30,"to":44}}}}],["4bfdbff6-1588-4cc4-9732-7e1bf3bfa67a",{"pageContent":"tothetestteam)toensurethatsolutionsmeetbusinessrequirements\n•ExtensivelyexecutedT-SQLqueriesinordertoviewsuccessfultransactionsofdataandfor\nvalidatingdatainSqlServerDatabas\n•UsedSplunkAnalyticsforreportingonexternaldatasetslocatedinHadoop \n•StrongKnowledgeinprotocolslikeSSHandSCPandtestedtheapplicationinUnixEnviroment\n•UsedSqooptotransferdatafromoracleintoHadoopHDFSaswellexportingdatafromHadoop\nHDFSfiletoRDBMS\n•TestedthedimensionalcubesdevelopedbySQLServerAnalysisServices(SSAS)andqueried\nthedatausingSQLServerManagementstudio(SSMS)","metadata":{"source":"/tmp/resume-processor-sLMqmq/Raju_DA.DOCX.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Copy of Raju_N_DA.DOCX","Producer":"Skia/PDF m122 Google Docs Renderer"},"metadata":null,"totalPages":8},"loc":{"pageNumber":4,"lines":{"from":42,"to":50}}}}],["f067c545-88ed-4e48-97e6-0475e9916e67",{"pageContent":"•IdentifyingfieldanddatadefectswithrequiredinformationinETLprocessinvariousmappings\nandonetoonemapping.\n•TestedalltheETLprocessesdevelopedforfetchingdatafromHadoopHivesystemtothetarget\nDatawarehouseOracleusingcomplexSQLqueries.\n•PerformeddatavalidationontheflatfilesthatweregeneratedinUNIXandHadoopenvironment\nusingUNIXandHadoopfscommandsasnecessary\n• TestingHadoopHBaseprovisioningonVMwarevirtualizedplatform \n•TestedBeaconsthatgeneratedfromchormeatDataEnterpriseintegrationwithHadoop\n•Verifyingfillforwardmethodologyforrecordsthatarenotpartofdailyload\n•CreatedAdhocreportsfortestingnecessitiesagainstreportdatabase\n•Reportedthedefects/buginJiraticketsanddocumentedthereport.\n•WrittenTestCasesforETLtocompareSourceandTargetdatabasesystems.\nEnvironment:Agile,SQLServer2008R2,Guidwire,Talend,Netezza,Microstratgegy9.2,WinSCP,Oracle10g,\nFlatfiles,TOAD,SQLServerManagementstudio(SSMS),V-SQL,TFS,Jira,UNIX,SSH,UNIXShellScript","metadata":{"source":"/tmp/resume-processor-sLMqmq/Raju_DA.DOCX.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Copy of Raju_N_DA.DOCX","Producer":"Skia/PDF m122 Google Docs Renderer"},"metadata":null,"totalPages":8},"loc":{"pageNumber":5,"lines":{"from":1,"to":14}}}}],["31707693-0a25-497f-8187-837f5b401b8d",{"pageContent":"Environment:Agile,SQLServer2008R2,Guidwire,Talend,Netezza,Microstratgegy9.2,WinSCP,Oracle10g,\nFlatfiles,TOAD,SQLServerManagementstudio(SSMS),V-SQL,TFS,Jira,UNIX,SSH,UNIXShellScript\n,Python,Vertica,Netezza,Sqlserver,Oracle,SourceTree,GitHub,QuerySurge,Beackoning,Source\nTree,nformatica,Glitch,Hive,Tableau,Informatica,ApacheAnt,Mobaxterm,pyunit,AquaStudio,Beyond\nCompare,Winmerge,HadoopHive,Tidal,Cronjob,Jenkins,splunk\nEntertainmentPartners,Burbank,CA(April2013–October2014)\nSrBusinessDataAnalyst–Vista5\nVista5isanapplicationDevelopedbytheEntertainmentpartnerstomeetthecorporateproductionaccountingneedsat\nthedetaillevelforAllExpensesandBudgetsofJournalEntries,GeneralLedgers,TrialBalancesandPayrollNeeds\nCorporationunitspresentinEntertainmentIndustry.thisreuquirementisdevelopedtofoundoutthediscrapnciesforthe\nweeklyreconciliations,dataintegrity,datamigrationofthelogicalsetforthereportsfromETLdata\n•InvolvedinBusinessanalysisandrequirementsgathering.","metadata":{"source":"/tmp/resume-processor-sLMqmq/Raju_DA.DOCX.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Copy of Raju_N_DA.DOCX","Producer":"Skia/PDF m122 Google Docs Renderer"},"metadata":null,"totalPages":8},"loc":{"pageNumber":5,"lines":{"from":13,"to":24}}}}],["aee1918b-2cbf-455b-810b-493aef9288cf",{"pageContent":"weeklyreconciliations,dataintegrity,datamigrationofthelogicalsetforthereportsfromETLdata\n•InvolvedinBusinessanalysisandrequirementsgathering.\n•Tested/Foundthedefectsinuniversesandreports.UsedMinglefortrackingthedefects.\n•TestedalldatareportspublishedtoWebincludingdashboards,summarized,master-detailedand\nAPI’s.\n•Testedgraphsforextracting,cleansing,transforming,integrating,andloadingdatausingData\nStageETLTool.\n•WorkedwithBigDataandHadoopFileSystem\n•WorkedasETLTesterresponsiblefortherequirements/ETLAnalysis,ETLTestingand\ndesigningoftheflowandthelogicfortheDatawarehouseproject.\n•AnalyzeddatausingHadoopcomponentsHiveandPig\n•InvolvedwithDevelopersinloadingdatafromedgenodetoHDFSusingshellscripting.\nTestedthedatathatwasloadedontoHDFS.\n•ValidatedtheprocessofLoadandtransformlargesetsofstructured,semistructuredand\nunstructureddatausingHadoop/BigDataconcepts\n•ResponsibleforprovidingDiscrepanciesofDataReconciliationreportsaccordingtoclient’s\nrequirementusingMSAccess.","metadata":{"source":"/tmp/resume-processor-sLMqmq/Raju_DA.DOCX.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Copy of Raju_N_DA.DOCX","Producer":"Skia/PDF m122 Google Docs Renderer"},"metadata":null,"totalPages":8},"loc":{"pageNumber":5,"lines":{"from":23,"to":39}}}}],["1f645df4-8b80-4a3d-a6a2-3ebf76479e6d",{"pageContent":"unstructureddatausingHadoop/BigDataconcepts\n•ResponsibleforprovidingDiscrepanciesofDataReconciliationreportsaccordingtoclient’s\nrequirementusingMSAccess.\n•Performed dataanalysis and dataprofiling usingcomplex SQL onvarioussourcessystems\nincludingOracleand Teradata.\n•UsedPuttytoconnecttoUNIXusingSSHprotocol,InternetExplorerandforwebbased\ncomponent\n•CreatedETLTestingprocessandvalidatebusinessrulesandpoliciestodataandtransformation\nincludingalldatapipelinesonhadoopclusters,monitoringdataactivitiesinHDFS,HIVEetc.\n•CreatedandcustomizedtheSettings.xmlfileforthelocalandserverconfigurationbuilds\n•CreatedShort-cutjoins,aliasesandcontextstomaketheuniverseloopsfree.\n•AtestreportingenvironmentwasestablishedtocombineDistributionWorkManagementand\ninformationintoaconsolidatedplacetoallowcombinedreportstobegenerated.","metadata":{"source":"/tmp/resume-processor-sLMqmq/Raju_DA.DOCX.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Copy of Raju_N_DA.DOCX","Producer":"Skia/PDF m122 Google Docs Renderer"},"metadata":null,"totalPages":8},"loc":{"pageNumber":5,"lines":{"from":37,"to":49}}}}],["000f87cb-a30e-4a0b-b77c-51a5694ffa3e",{"pageContent":"•Deployed.earBuild’sontoQAServerfromJbossandMavenforValidationofReportsthrough\nPuttyandWinscp\n•Deleted/AddedPermissionfortheusersinSQLServertoaccessbuildcreatedlocallyandserver\nside\n•LocallyCreatedtheBuildMavenwithClearCaseVersionfortheUserstoaccessthereports\nFromthisBuildfordatavalidation\n•DevelopETLtestplansbasedonteststrategy.Createdandexecutedtestcasesandtestscripts\nbasedonteststrategyandtestplansbasedonETLMappingdocument.\n•Testedandworkedoncreatingopendocumentreportsforbusiness.\n•Usedvarious@Functionslike@Prompt(foruserdefinedqueries),@Where(Forcreating\nconditionalfilters),and@SelectfortestingBusinessReportswithvariousboundaryconditions.\n•PreparationoftechnicalspecificationsandSourcetoTargetmappings.\n•ExtensivelyusedSQLprogramminginbackendandfront-endfunctions,procedures,packagesto\nimplementbusinessrulesandsecurity\n•ExperiencedusingquerytoolsforSQlServertovalidatereportsandtroubleshootdataquality\nissues.","metadata":{"source":"/tmp/resume-processor-sLMqmq/Raju_DA.DOCX.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Copy of Raju_N_DA.DOCX","Producer":"Skia/PDF m122 Google Docs Renderer"},"metadata":null,"totalPages":8},"loc":{"pageNumber":6,"lines":{"from":1,"to":16}}}}],["0ffb352a-4617-4f5a-876d-bc8a654a434f",{"pageContent":"implementbusinessrulesandsecurity\n•ExperiencedusingquerytoolsforSQlServertovalidatereportsandtroubleshootdataquality\nissues.\n•SolidtestingexperienceinworkingwithSQLStoredProcedures,triggers,viewsandworkedwith\nperformancetuningofcomplexSQLqueriesforbetterperformanceandefficiency.\n•Validatedformatofthereportsandfeeds.\n•EffectivelycommunicateDataAnalysisandtestingactivitiesandfindingsinoralandwritten\nformats.\n•ExtracteddatafromvarioussourceslikeflatfilesandSQLServer.\n•Designingandcreationofcomplexmappingsusinginvolvingtransformationssuchasexpression,\njoiner,aggregator,lookup,updatestrategy,andfilter.\n•CreatedvariousPL/SQLstoredproceduresfordroppingandrecreatingindexesontargettables.\n•Workedonissueswithmigrationfromdevelopmenttotesting.\n•DeployedthebuildsandReportscorrespondingusingmvncommandsonlocalandservers\nmachines\n•RestoredDatabasesandcreatedbackupsintoSQlserverfrombackups\n•Verifiedmigrationfromdifferentdatabases(i.e.Teradata,Oracle,MySQL)toHadoop","metadata":{"source":"/tmp/resume-processor-sLMqmq/Raju_DA.DOCX.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Copy of Raju_N_DA.DOCX","Producer":"Skia/PDF m122 Google Docs Renderer"},"metadata":null,"totalPages":8},"loc":{"pageNumber":6,"lines":{"from":14,"to":30}}}}],["e27b423a-fcac-437d-b3ac-01ebcb0ffa36",{"pageContent":"machines\n•RestoredDatabasesandcreatedbackupsintoSQlserverfrombackups\n•Verifiedmigrationfromdifferentdatabases(i.e.Teradata,Oracle,MySQL)toHadoop\nEnvironment:Mingle,Jboss,Maven,Putty,Winscp,ClearCase,DataStage,MSAccess,SqlServer2008R2,Data\nStage8.0.1,Agile/ScrumMethodologies,SAP,Eclipse,XMLFiles,MSExcel,,Erwin4.0,UnixSSH\nScripting,Bussinessobjects,Connx,Linux,BussinessObjects,Hadoop,HDSF\nBankofAmerica(Accenture),AgouraHills,CA(July2011–March2013)\nSystemsDataAnalyst\nResponsibilities:\n•AssistedincreatingfactanddimensiontableimplementationinStarSchemamodelbasedon\nrequirements.\n•Developtestplansbasedonteststrategy.Createdandexecutedtestcasesbasedonteststrategy\nandtestplansbasedonETLMappingdocument.\n•PreparationoftechnicalspecificationsandSourcetoTargetmappings.\n•ExtensivelyusedSQLprogramminginbackendandfront-endfunctions,procedures,packagesto\nimplementbusinessrulesandsecurity\n•WrittentestcasestotesttheapplicationmanuallyinQualityCenterandautomatedthemin\nStoredProceduresusingSSMS","metadata":{"source":"/tmp/resume-processor-sLMqmq/Raju_DA.DOCX.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Copy of Raju_N_DA.DOCX","Producer":"Skia/PDF m122 Google Docs Renderer"},"metadata":null,"totalPages":8},"loc":{"pageNumber":6,"lines":{"from":28,"to":45}}}}],["9b0270fa-bc42-48a4-8cdb-b53fe82a0f83",{"pageContent":"implementbusinessrulesandsecurity\n•WrittentestcasestotesttheapplicationmanuallyinQualityCenterandautomatedthemin\nStoredProceduresusingSSMS\n•ExperiencewithExcelReportsanddynamicdashboards,scorecardsandstructuredreportsfor\noperationsandhighermanagement.\n•Testedbothconditionalformattingandthresholdleveltestingforseveralreportsdevelopedin\nCognosandExcel.","metadata":{"source":"/tmp/resume-processor-sLMqmq/Raju_DA.DOCX.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Copy of Raju_N_DA.DOCX","Producer":"Skia/PDF m122 Google Docs Renderer"},"metadata":null,"totalPages":8},"loc":{"pageNumber":6,"lines":{"from":43,"to":49}}}}],["afe69803-9e15-4a10-8924-c2a3c201da70",{"pageContent":"•Analysis offunctionaland non-functional categorizeddataelementsfordataprofiling\nandmappingfromsourcetotargetdataenvironment.Developedworkingdocumentstosupportfindingsand\nassignspecifictasks\n•Involvedwith data profiling formultiplesourcesandanswered complexbusinessquestionsby\nprovidingdatatobusinessusers.\n•WroteKornscriptsin UNIX and LINUX environmenttoverifytheremoteloadingprocess\nusingFsecure,Ssh,Rsh shellcommands\n•Tetsted.netCodeusedforthewebbasedreports\n•TestedSSISPackagesusedforDataExtraction,TransformationandLoading\n•UsedvariousSSIStaskssuchaasconditionalsplit,DerivedColumnonthedata\nretrieved,performedDataValidationChecksduringstagingandthenloadedthedata\n•PreparedseveraltestscenariosfortheworkflowoftheentireETLcycle\n•DevelopedanddocumenteddataMappings/Transformations,andSqLsessionsasperthebusiness\nrequirement.InvolvedinthedevelopmentMappingsandalsotunedthemforbetterperformance.\n•ExtensiveexperienceinwritingSQLandPL/SQLscriptstovalidatethedatabasesystemsandfor","metadata":{"source":"/tmp/resume-processor-sLMqmq/Raju_DA.DOCX.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Copy of Raju_N_DA.DOCX","Producer":"Skia/PDF m122 Google Docs Renderer"},"metadata":null,"totalPages":8},"loc":{"pageNumber":7,"lines":{"from":1,"to":15}}}}],["40b78a5f-13a0-494c-9a42-eb036732bb25",{"pageContent":"requirement.InvolvedinthedevelopmentMappingsandalsotunedthemforbetterperformance.\n•ExtensiveexperienceinwritingSQLandPL/SQLscriptstovalidatethedatabasesystemsandfor\nbackenddatabasetesting.\n•PerformedFunctionalTestingandBack-endTestingusingthedatabasecomparableresults\nmanually.\n•Loadnewormodifieddataintoback-endOracleandSQLServerdatabases.\n•TestedScheduledSSISPackageswhichranwithSQLAgentwhichareconfiguredlinkedservers\nfordataaccessbetweennewandoldservers\n•CreatedTables,GraphsandListingsforUserReports\n•CoordinatedwithAgileteamsandimplementedallTestPlansinaccordancetoneedof\ndevelopmentprojects\n•DevelopedautomatedtestscriptsfrommanualtestcasesforRegressiontestingbasedonthe\nrequirementdocumentsusingQuickTestProfessional.\n•Defectsidentifiedintestingenvironmentwherecommunicatedtothedevelopersusingdefect\ntrackingtoolMercuryTestDirector.\n• TestingHadoop(Both1.Xand2.X)provisioningonVMwarevirtualizedplatform \n•Implement,Gather,andreportteamandprojectmetricswhichdemonstratebusinessvalueand","metadata":{"source":"/tmp/resume-processor-sLMqmq/Raju_DA.DOCX.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Copy of Raju_N_DA.DOCX","Producer":"Skia/PDF m122 Google Docs Renderer"},"metadata":null,"totalPages":8},"loc":{"pageNumber":7,"lines":{"from":14,"to":30}}}}],["7d011bf1-7d42-43a4-8ec3-02da3ccbe63f",{"pageContent":"trackingtoolMercuryTestDirector.\n• TestingHadoop(Both1.Xand2.X)provisioningonVMwarevirtualizedplatform \n•Implement,Gather,andreportteamandprojectmetricswhichdemonstratebusinessvalueand\nshowingcontinousimprovementinanAgileenvironment.\n•Developedscripts,utilities,simulators,datasetsandotherprogrammatictesttoolsasrequired\nexecutingtestplans.\n•Effectivelycommunicatetestingactivitiesandfindingsinoralandwrittenformats.\n•ReportedbugsandtrackeddefectsusingQualityCenter11\n•ExtensivelyusedInformaticapowercenterforextraction,transformationandloadingprocess.\n•WorkedwithETLgroupforunderstatingmappingsfordimensionsandfacts.\n•ExtracteddatafromvarioussourceslikeOracle,flatfilesandSQLServer.\n•Workedonissueswithmigrationfromdevelopmenttotesting.\nEnvironment:SSIS,Siperian,HPQualityCenter11and9.2,Oracle10g,Erwin4.0,XML,XSLT,UNIX,Shell\nScripting,SOAPUI,WebServices,SQlServer2008,WSDL,AutomatedUITesting,SOATest5.5.2,SQL,PL/SQL,","metadata":{"source":"/tmp/resume-processor-sLMqmq/Raju_DA.DOCX.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Copy of Raju_N_DA.DOCX","Producer":"Skia/PDF m122 Google Docs Renderer"},"metadata":null,"totalPages":8},"loc":{"pageNumber":7,"lines":{"from":28,"to":41}}}}],["b835bc6e-5d26-4fe5-b255-3c4f2c5b3b17",{"pageContent":"Environment:SSIS,Siperian,HPQualityCenter11and9.2,Oracle10g,Erwin4.0,XML,XSLT,UNIX,Shell\nScripting,SOAPUI,WebServices,SQlServer2008,WSDL,AutomatedUITesting,SOATest5.5.2,SQL,PL/SQL,\nTOAD7.0,Cognos,MSExcel,Agile/ScrumMethodologies,PivotTables,MicrosoftVisualStudio2008,Mircrosfot\nSilverlight.\nPreviousExperiences\nMICROSOFT,REDMOND,WA\n♦\nDATAWAREHOUSEANALYST\n♦\nJAN-11–\nJUNE11","metadata":{"source":"/tmp/resume-processor-sLMqmq/Raju_DA.DOCX.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Copy of Raju_N_DA.DOCX","Producer":"Skia/PDF m122 Google Docs Renderer"},"metadata":null,"totalPages":8},"loc":{"pageNumber":7,"lines":{"from":40,"to":50}}}}],["99b2aef7-7e3d-4448-a63d-2ba791144430",{"pageContent":"LIBERTYMUTUAL,Dover,NH\n♦\nProgrammerAnalyst\n♦\nJul-09–Dec\n10\nTechnicalSkills\nDataModelingTools.Erwin.\nETLToolsInformaticaPC/PWX,Spark,Hive,AWSGlue,\nDatabricks,Qubole,Datastage\nReportingToolsIBMUnica,Microstrategy,Tableau,Cognos\nDatabasesOracle,IBMDB2,MSSQLServer,MySQL,Postgres,\nRedshift,Vertica,Db2,Teradata,SQLServer2008/2010\nNoSQLDatabasesMongoDB,DynamoDB,Cassandra\nBusinessIntelligence.Tableau,MicroStrategy\nProgramLanguages.SQL,PL/SQL,Java,Python,ShellScripting\nAWSServicesEC2,S3,EMR,Glue,Lambda,Elasticsearch.\nCertifications\nAmazonWebService(AWS)CertifiedSolutionArchitectAssociate\nMicrosoftPL/SQLCertification\nEducation\nFairfax,VirginiaStratfordUniversityJan2007-Dec2008\nMaster’sinComputerEngineering,December2008.\nGraduateCoursework:SoftwareDevelopment,InternetTechnologiesandwebdevelopment,datanetworks,\nDataModeling,DatabaseSecurity,WebSitedevelopment,DataWarehousing,DataAnalytics,Advanced\nDatabasemanagement.\nHyderabad,IndiaJNTUJuly2002–May2006","metadata":{"source":"/tmp/resume-processor-sLMqmq/Raju_DA.DOCX.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Copy of Raju_N_DA.DOCX","Producer":"Skia/PDF m122 Google Docs Renderer"},"metadata":null,"totalPages":8},"loc":{"pageNumber":8,"lines":{"from":1,"to":27}}}}],["3f7c9f48-4f00-4c1c-8497-e9c300808c23",{"pageContent":"DataModeling,DatabaseSecurity,WebSitedevelopment,DataWarehousing,DataAnalytics,Advanced\nDatabasemanagement.\nHyderabad,IndiaJNTUJuly2002–May2006\nBachelor’sinComputerScienceandInformationTechnology,May2006.","metadata":{"source":"/tmp/resume-processor-sLMqmq/Raju_DA.DOCX.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Copy of Raju_N_DA.DOCX","Producer":"Skia/PDF m122 Google Docs Renderer"},"metadata":null,"totalPages":8},"loc":{"pageNumber":8,"lines":{"from":25,"to":28}}}}]],{"0":"3b0ce112-bd04-4652-a28f-719cd34ee07d","1":"dc59d854-b285-480d-b844-ab81d6c1ee8d","2":"01c00c14-ae7e-4036-a109-c751a1108626","3":"97701e15-7684-4077-a50a-8ab01f2c1b30","4":"99c82890-ffd0-4bd7-b0ad-d64635ed51f9","5":"9fd73a74-a455-481c-a811-59d98ae87979","6":"cf208e91-6ee5-43ff-abbc-0fdda8af96d6","7":"b08a2228-9aec-4847-b393-21fc7408a2c4","8":"f9cfefd9-62c9-4e06-a785-c95e2b8310fb","9":"6d563e6e-011e-4097-accc-1ca8b88f4522","10":"20f846cc-1730-4a59-9059-4ee431de0e87","11":"eb078586-bbff-4c0d-b323-fb3d5585e57a","12":"cb331347-3a9f-48ff-a90d-17db84837622","13":"b61586eb-9851-46fa-bdff-2588301f50cc","14":"4bfdbff6-1588-4cc4-9732-7e1bf3bfa67a","15":"f067c545-88ed-4e48-97e6-0475e9916e67","16":"31707693-0a25-497f-8187-837f5b401b8d","17":"aee1918b-2cbf-455b-810b-493aef9288cf","18":"1f645df4-8b80-4a3d-a6a2-3ebf76479e6d","19":"000f87cb-a30e-4a0b-b77c-51a5694ffa3e","20":"0ffb352a-4617-4f5a-876d-bc8a654a434f","21":"e27b423a-fcac-437d-b3ac-01ebcb0ffa36","22":"9b0270fa-bc42-48a4-8cdb-b53fe82a0f83","23":"afe69803-9e15-4a10-8924-c2a3c201da70","24":"40b78a5f-13a0-494c-9a42-eb036732bb25","25":"7d011bf1-7d42-43a4-8ec3-02da3ccbe63f","26":"b835bc6e-5d26-4fe5-b255-3c4f2c5b3b17","27":"99b2aef7-7e3d-4448-a63d-2ba791144430","28":"3f7c9f48-4f00-4c1c-8497-e9c300808c23"}]