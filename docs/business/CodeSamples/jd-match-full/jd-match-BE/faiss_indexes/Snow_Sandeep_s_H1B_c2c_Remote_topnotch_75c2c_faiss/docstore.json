[[["240468eb-56f6-4088-bffd-80216038dc03",{"pageContent":"Sandeep. Sanne \nEnterprise Architecture • Data Analytics • Snowflake • Teradata • AWS • Data Warehousing \n \n \nCell: 848.391.8938 \nE-mail: sandeepniky@gmail.com  \nLocation: Atlanta, GA \n \n \n \n \nEDUCATION \n \n \nBachelor of Technology \nJawaharlal Nehru Technological \nUniversity \n \nCERTIFICATIONS \n \n \nCOMPETENCIES \nProduct Development \nProject Planning & Execution \nScrum, Agile, & Waterfall \nMethodologies \nIT Project Management \nDatabase Optimization \nProject Roadmap Scheduling \nMigrations, Integrations, & \nImplementations \nEnd-to-End Business Solutions \nStakeholder Engagement \nBusiness Requirements Gathering & \nNeeds Analysis \nProcess Improvement Strategies \n \n \nPERSONAL SKILLS \nTechnology Teams Leadership \nCross Functional Collaboration \nInnovative Problem Solving \nStrong Technical Judgement \nSelf-Starter / Thought-Leader \n \n \n \n \n \n \n \n \nSUMMARY \nConceptualizes  and  delivers  enterprise  data warehousing  projects by  designing  and  deploying  the  Data warehousing","metadata":{"source":"/tmp/resume-processor-nRDEgV/Snow_Sandeep_s_H1B_c2c_Remote_topnotch_75c2c.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Author":"Kevin Bottino","Creator":"Microsoft® Word 2016","Producer":"www.ilovepdf.com","CreationDate":"D:20240517120917+00'00'","ModDate":"D:20240517120917Z"},"metadata":null,"totalPages":2},"loc":{"pageNumber":1,"lines":{"from":1,"to":54}}}}],["5a752a1f-edc0-4e1f-9c21-15699ca47257",{"pageContent":"Self-Starter / Thought-Leader \n \n \n \n \n \n \n \n \nSUMMARY \nConceptualizes  and  delivers  enterprise  data warehousing  projects by  designing  and  deploying  the  Data warehousing \nsolutions. Subject Matter Expert and technical Leader for data engineering, service delivery involving Snowflake, Teradata, \nData  warehousing and ETL. Involved  in  business requirement  gathering,  collaborates  with  stakeholders,  and  supports  to \ndevelop project plans. Drives business solutions to improve productivity, enable cost-savings and revenue generation. \n \n \n \nPROFESSIONAL EXPERIENCE \nTech Lead - data engineering - Snowflake                   Elevance Health (Client) | 03/2019 to Present | \n                                                                                              Cognitive Artificial Intelligence \n \nMajor Accomplishments:  \n Designed and delivered ETL on Snowflake for Impact Tracking application developed to assess different core","metadata":{"source":"/tmp/resume-processor-nRDEgV/Snow_Sandeep_s_H1B_c2c_Remote_topnotch_75c2c.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Author":"Kevin Bottino","Creator":"Microsoft® Word 2016","Producer":"www.ilovepdf.com","CreationDate":"D:20240517120917+00'00'","ModDate":"D:20240517120917Z"},"metadata":null,"totalPages":2},"loc":{"pageNumber":1,"lines":{"from":44,"to":66}}}}],["411f4be4-1a8b-4091-8579-3baee10cd96a",{"pageContent":"Major Accomplishments:  \n Designed and delivered ETL on Snowflake for Impact Tracking application developed to assess different core \nprograms, identify cost, utilization and other metrics for members in different cost of care programs. \n Designed and implemented ETL on Snowflake for Risk score rebuild process for Medicaid data, changed the on-\nprem user owned process replaced with cloud-based Snowflake processing fed to Python models for risk scoring. \n Lead the team that Implemented multiple ETL projects in Enterprise data management (EDM) area in Teradata \nand Snowflake. Worked on designing, implementing and optimizing data solutions. \n Designed and Implemented Automated balancing process completely in Teradata with alert emails at different \nsteps of the balancing process from an old approach involving manual process. \n \nResponsibilities \n• Design,  develop  and  implement  database  systems  for  the  largescale  applications  to  store  structured  and","metadata":{"source":"/tmp/resume-processor-nRDEgV/Snow_Sandeep_s_H1B_c2c_Remote_topnotch_75c2c.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Author":"Kevin Bottino","Creator":"Microsoft® Word 2016","Producer":"www.ilovepdf.com","CreationDate":"D:20240517120917+00'00'","ModDate":"D:20240517120917Z"},"metadata":null,"totalPages":2},"loc":{"pageNumber":1,"lines":{"from":65,"to":76}}}}],["12b624cf-7387-4cff-b2ce-2bdf81739149",{"pageContent":"Responsibilities \n• Design,  develop  and  implement  database  systems  for  the  largescale  applications  to  store  structured  and \nunstructured data into enterprise data warehouse, Develop & Maintain database and safeguards to increase \nperformance and establish robust techniques for data storage and retrieval. \n• Managing  Database,  ETL  including,  Project  reporting,  Resourcing,  Weekly  Reports,  Status  Reports  and \nproviding technical support to the Entire Team. \n• Interacted  with  the  Business  Users  to  analyze  the  business requirements  and  transform  the  business \nrequirements into the technical requirements. \n• Component wise estimation, project planning & solution designing of data processing using Snowflake. \n• Developing ETL application from the Atomic and Semantic Layers, by developing and maintaining the code \ncomponents  using Snow SQL, Teradata SQL  and Utilities. script  development  in  snowflake  and  execution \nusing AWS glue & step functions.","metadata":{"source":"/tmp/resume-processor-nRDEgV/Snow_Sandeep_s_H1B_c2c_Remote_topnotch_75c2c.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Author":"Kevin Bottino","Creator":"Microsoft® Word 2016","Producer":"www.ilovepdf.com","CreationDate":"D:20240517120917+00'00'","ModDate":"D:20240517120917Z"},"metadata":null,"totalPages":2},"loc":{"pageNumber":1,"lines":{"from":75,"to":86}}}}],["5855c6cc-aad8-4413-ae59-96eb25809895",{"pageContent":"components  using Snow SQL, Teradata SQL  and Utilities. script  development  in  snowflake  and  execution \nusing AWS glue & step functions. \n• Perform  ETL  operations,  extract  data  from  various  sources,  perform  transformations  on  data  by  applying \nrules,  lookup  tables,  and  transformations,  and  further  load  the  transformed  data  into  database  designed \nwith unique data models and schemas.  \n• Perform data analysis on huge amount of data sets and create modeling and development of the Enterprises \ndata  loading  ETL/ELT  solution.  Performing  data  profiling  of  existing applications automate  the  process  of \ncollecting data from multiple data sources. \n• Developing   source-to-target   mapping   and   business   rules   (e.g.,   transformation   logic)   through   the \ndevelopment of the logical data integration models needed to fulfill the data integration requirements.","metadata":{"source":"/tmp/resume-processor-nRDEgV/Snow_Sandeep_s_H1B_c2c_Remote_topnotch_75c2c.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Author":"Kevin Bottino","Creator":"Microsoft® Word 2016","Producer":"www.ilovepdf.com","CreationDate":"D:20240517120917+00'00'","ModDate":"D:20240517120917Z"},"metadata":null,"totalPages":2},"loc":{"pageNumber":1,"lines":{"from":85,"to":94}}}}],["adeb5be8-c02e-46ee-8bd3-7054fa822b39",{"pageContent":"development of the logical data integration models needed to fulfill the data integration requirements. \n• Responsible  for  troubleshooting  database  issues  and  engaged  in  problem  solving  tasks  involving  data \ntransformations.    Responsible  for  performing  performance  tuning  Informatica,  Teradata,  SQL,  Unix  shell \nScripting.   \n• Collaborated with the stakeholders in building the Technology Strategy for the Organization and assured to \nalign  with  the  Enterprise  Strategic  Initiatives,  Business  Objectives  and  Technology  Capabilities. Conducted \nworking sessions and brainstormed ideas to implement best-in-class solutions for the stakeholders. \n• Adopted  agile  frameworks  for  the  product  development  life  cycle,  planned product increments,  scoped \nfeatures, and executed Scrum.  \n• Acted as a liaison between business and technology partners and helped bridge the gaps in understandings","metadata":{"source":"/tmp/resume-processor-nRDEgV/Snow_Sandeep_s_H1B_c2c_Remote_topnotch_75c2c.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Author":"Kevin Bottino","Creator":"Microsoft® Word 2016","Producer":"www.ilovepdf.com","CreationDate":"D:20240517120917+00'00'","ModDate":"D:20240517120917Z"},"metadata":null,"totalPages":2},"loc":{"pageNumber":1,"lines":{"from":94,"to":103}}}}],["c99028b5-3ce5-40a5-96eb-9665dfab5571",{"pageContent":"features, and executed Scrum.  \n• Acted as a liaison between business and technology partners and helped bridge the gaps in understandings \nwhich led to a successful application delivery on time and meeting all required SLA’s. \n• Involved in Cost Optimization, defining best practices, cost Forecasting and analysis.","metadata":{"source":"/tmp/resume-processor-nRDEgV/Snow_Sandeep_s_H1B_c2c_Remote_topnotch_75c2c.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Author":"Kevin Bottino","Creator":"Microsoft® Word 2016","Producer":"www.ilovepdf.com","CreationDate":"D:20240517120917+00'00'","ModDate":"D:20240517120917Z"},"metadata":null,"totalPages":2},"loc":{"pageNumber":1,"lines":{"from":102,"to":105}}}}],["d57bf6e7-952e-4300-b6ad-94c137fb5f3d",{"pageContent":"Tech Lead & Senior Consultant | Teradata           \nUTIS - 01/2019 to 03/2019            \nCapgemini - 05/2013 to 12/2018  \n \nProject Name: Teradata – EOL (Computer Associates) \nProject Name: CCR -Data Acquisitions & Data Marts (Coca-Cola Company, North America) \nProject Name: FAA (Finance Agility & Analytics) - (Unilever PLC) \n                                                                        Senior  consultant, Capgemini  data  analytics  team – Worked as  technology  lead in  multiple  projects  handling ETL projects. \nDesigned and Developed ETL using Teradata as a primary area of work. Worked as a Physical data modeler, designed ETL workflows. Lead multi-person cross-functional \nteam through technical project management initiatives. Aligns corporate initiatives with security methodologies to ensure compliance with regulations. Leads next-","metadata":{"source":"/tmp/resume-processor-nRDEgV/Snow_Sandeep_s_H1B_c2c_Remote_topnotch_75c2c.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Author":"Kevin Bottino","Creator":"Microsoft® Word 2016","Producer":"www.ilovepdf.com","CreationDate":"D:20240517120917+00'00'","ModDate":"D:20240517120917Z"},"metadata":null,"totalPages":2},"loc":{"pageNumber":2,"lines":{"from":2,"to":11}}}}],["217d7cbd-2c75-433f-8552-658d4590dba1",{"pageContent":"team through technical project management initiatives. Aligns corporate initiatives with security methodologies to ensure compliance with regulations. Leads next-\ngeneration initiatives to strengthen IT team to learn new technologies. Delivers techniques/knowledge necessary to convert to data-driven strategies as key advisor. \n• Managing Database, ETL including, Project reporting, Resourcing, Weekly Reports, Status Reports and providing technical support to the Entire Team. \n• Interacted with the Business Users to analyze the business requirements and transform the business requirements into the technical requirements. \n• Analysis of the functional Specification and Business requirement documents, developing technical design documents and mapping documents. \n• Constructed context diagrams and data-flow diagrams based on a description of a business process. \n• Analysis, consistency, accuracy, referential integrity, cleanses and consolidates data before loading into data warehouse.","metadata":{"source":"/tmp/resume-processor-nRDEgV/Snow_Sandeep_s_H1B_c2c_Remote_topnotch_75c2c.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Author":"Kevin Bottino","Creator":"Microsoft® Word 2016","Producer":"www.ilovepdf.com","CreationDate":"D:20240517120917+00'00'","ModDate":"D:20240517120917Z"},"metadata":null,"totalPages":2},"loc":{"pageNumber":2,"lines":{"from":11,"to":17}}}}],["99070bbf-20e1-421d-a651-cb2afe2e0ac8",{"pageContent":"• Analysis, consistency, accuracy, referential integrity, cleanses and consolidates data before loading into data warehouse. \n• Worked on performance tuning of Teradata query, PI, SI, PPI Indexing, use of Compression of columns, stats collection, Performance tuning of SQL. \n• Responsible for migrating the current DWH from Teradata to Azure Cloud (Blob). \n• Analysis of the current ETL jobs to capture all transformations from source to target and recreating similar ETL jobs to load data to Azure SQL Warehouse \n• Component wise estimation, project planning & solution designing of data processing. \n• Developing Technical designs based on the existing ETL’s in Teradata & Informatica \n• Re-engineering some of the existing system functionalities to avoid existing redundancies & anomalies. \n• Interacting with Architecture/ETL teams on new design/development approaches \n• Data modeling in Erwin; design of target data models for enterprise data warehouse","metadata":{"source":"/tmp/resume-processor-nRDEgV/Snow_Sandeep_s_H1B_c2c_Remote_topnotch_75c2c.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Author":"Kevin Bottino","Creator":"Microsoft® Word 2016","Producer":"www.ilovepdf.com","CreationDate":"D:20240517120917+00'00'","ModDate":"D:20240517120917Z"},"metadata":null,"totalPages":2},"loc":{"pageNumber":2,"lines":{"from":17,"to":25}}}}],["4f0bd168-8419-4f5b-b61d-1515f244dc45",{"pageContent":"• Interacting with Architecture/ETL teams on new design/development approaches \n• Data modeling in Erwin; design of target data models for enterprise data warehouse   \n• Translate detailed physical design into DDL & worked on the data model mapping document. \n• Create the Source to Target Physical Mapping by mapping source data elements to PDM. \n \nADDITIONAL EXPERIENCE \nSenior Software engineer                                                                         Mahindra Satyam | 01/2007 to 04/2013 \n \nProject Name: ETL Acquisitions Projects and Data marts (Barclays Bank) \n• Interaction with business teams and users to understand the business requirements. \n• Developing Technical design documents based on the functional / requirement document. \n• Interacting with the Architecture team on designing solutions \n• Scripting using Teradata-BTEQ through Mainframes & writing SQL members, which include transformations. Converted a multilevel and redundant SQL","metadata":{"source":"/tmp/resume-processor-nRDEgV/Snow_Sandeep_s_H1B_c2c_Remote_topnotch_75c2c.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Author":"Kevin Bottino","Creator":"Microsoft® Word 2016","Producer":"www.ilovepdf.com","CreationDate":"D:20240517120917+00'00'","ModDate":"D:20240517120917Z"},"metadata":null,"totalPages":2},"loc":{"pageNumber":2,"lines":{"from":24,"to":36}}}}],["42f188a0-fb8c-43cb-9369-0bf917a1d44d",{"pageContent":"• Scripting using Teradata-BTEQ through Mainframes & writing SQL members, which include transformations. Converted a multilevel and redundant SQL \nprocess into one simplistic BTEQ script. \n• Used Teradata utilities like Multiload and Fast Load to load data into Teradata data warehouse.  \n• Performance tuning of SQL (Explain plans, Collect statistics, Primary/Secondary Indexes) \n• Supported Unit Testing and System Integration Testing (SIT) based on business. \n \nTECHNICAL PROFICIENCIES \n \nCloud Computing: Amazon Web Services, Microsoft Azure \nData Warehousing : Snowflake, Teradata V2R16, Azure DWH, Hive \nETL/ELT Tool: Snow SQL, Teradata Utilities (Fast Load, Multiload, Fast Export, BTEQ), Informatica, AWS Glue, Spark, DBT \nProgramming: SQL, Python \nMethodologies: Data warehousing, Data Marts, Data Mining, cloud data warehousing \nData Modeling Tool: ERWIN \nBig Data: Spark, Hive, Pig, Sqoop. \nTools: Kafka streaming, Apache Airflow,  \nData Visualization: Tableau","metadata":{"source":"/tmp/resume-processor-nRDEgV/Snow_Sandeep_s_H1B_c2c_Remote_topnotch_75c2c.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Author":"Kevin Bottino","Creator":"Microsoft® Word 2016","Producer":"www.ilovepdf.com","CreationDate":"D:20240517120917+00'00'","ModDate":"D:20240517120917Z"},"metadata":null,"totalPages":2},"loc":{"pageNumber":2,"lines":{"from":36,"to":52}}}}]],{"0":"240468eb-56f6-4088-bffd-80216038dc03","1":"5a752a1f-edc0-4e1f-9c21-15699ca47257","2":"411f4be4-1a8b-4091-8579-3baee10cd96a","3":"12b624cf-7387-4cff-b2ce-2bdf81739149","4":"5855c6cc-aad8-4413-ae59-96eb25809895","5":"adeb5be8-c02e-46ee-8bd3-7054fa822b39","6":"c99028b5-3ce5-40a5-96eb-9665dfab5571","7":"d57bf6e7-952e-4300-b6ad-94c137fb5f3d","8":"217d7cbd-2c75-433f-8552-658d4590dba1","9":"99070bbf-20e1-421d-a651-cb2afe2e0ac8","10":"4f0bd168-8419-4f5b-b61d-1515f244dc45","11":"42f188a0-fb8c-43cb-9369-0bf917a1d44d"}]