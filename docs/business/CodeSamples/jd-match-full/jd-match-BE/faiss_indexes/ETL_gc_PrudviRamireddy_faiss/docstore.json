[[["8df23e61-596f-4303-95cf-89a06a20fa17",{"pageContent":"Prudvi Ramireddy                                                                                                                                             \nMobile  : 331-444-3599. \nEmail     :  prudviramreddy@gmail.com \n \n \nPROFESSIONAL SUMMARY:                                                                                                                           \n Data Engineer professional with 11 years of experience in the Extraction, Transformation and \nLoading (ETL) on large scale development efforts leveraging industry standard using Talend DI \nand BigData. \n Design, Development, implementation and Support development of Enterprise Data \nWarehouse, entirely as Talend Developer which includes Experience in Data warehousing. \n 11 years of Experience in using Talend Data Integration and BigData (7.x/6.x/5.x) on different \nsource and target systems are Databases like SAP S/4HANA, Teradata, Oracle, SQL Server, Oracle","metadata":{"source":"/tmp/resume-processor-NZq5ma/ETL_gc_PrudviRamireddy.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Author":"Prudvi Ramireddy","Creator":"Microsoft® Word 2016","Producer":"www.ilovepdf.com","CreationDate":"D:20230518204532+00'00'","ModDate":"D:20230518204534Z"},"metadata":null,"totalPages":7},"loc":{"pageNumber":1,"lines":{"from":1,"to":13}}}}],["f11c961b-af4e-419f-8230-f3a229a7042d",{"pageContent":" 11 years of Experience in using Talend Data Integration and BigData (7.x/6.x/5.x) on different \nsource and target systems are Databases like SAP S/4HANA, Teradata, Oracle, SQL Server, Oracle \nand Cloud like S3 Bucket, Azure Blob, Azure Synapse, Snowflake, redshift and  files like  Excel, \nCSV, RPT, XML, JSON files into Data Warehousing. \n Exposure in vairious ETL Tools like Azure Data Factory, Azure Data Bricks, BODS, Informatica and \nAWS Glue. \n 2 years of experience in SAP S/4HANA using tSAPHanaConnection, tSAPHanaInput,  \ntSAPHanaOutput, tSAPHanaRollback, tSAPHanaCommit..etc \n Exposer in various ETL Tools like BODS Azure Data Factory, Informatica and AWS Glue. \n 4 years of experience in developing  Business  Intelligence  solutions  using  On-prem  and  Cloud \ntechnologies. \n 1 year experience in developing and implementing Talend Data Catalog / Data Lineage. \n Having Experience in Hadoop components like Hive, sqoop, pig, hdfs etc.,","metadata":{"source":"/tmp/resume-processor-NZq5ma/ETL_gc_PrudviRamireddy.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Author":"Prudvi Ramireddy","Creator":"Microsoft® Word 2016","Producer":"www.ilovepdf.com","CreationDate":"D:20230518204532+00'00'","ModDate":"D:20230518204534Z"},"metadata":null,"totalPages":7},"loc":{"pageNumber":1,"lines":{"from":12,"to":24}}}}],["3ea54c97-10c6-4532-9711-c525e4dd3aae",{"pageContent":"technologies. \n 1 year experience in developing and implementing Talend Data Catalog / Data Lineage. \n Having Experience in Hadoop components like Hive, sqoop, pig, hdfs etc., \n Having Experience in AWS components like DataPipeline, S3, EMR, EC2 etc., \n Hands on experience in creating S3 Buckets in AWS and loading data into Snowflake database. \n Created complex mappings in Talend 7.3 using tMap, tJoin, tReplicate, tParallelize, tJava, \ntAggregateRow, tDie, tWarn, tLogCatche..etc. \n Worked on Amazon S3 components ts3get, ts3put..etc. \n Experience with connection functionality to databases (Oracle, RDS, MySQL, Postgres, etc), files, \nand Azure blob, AWS S3, FTP and SAP. \n Capable of analyzing the business requirements and creating Mappings using Talend. \n Designed Technical Design Specifications and Mapping Documents with Transformation Rules. \n Strong knowledge on implementing SCD Type-1, Type-2 and Type-3 Dimensional tables and Facts.","metadata":{"source":"/tmp/resume-processor-NZq5ma/ETL_gc_PrudviRamireddy.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Author":"Prudvi Ramireddy","Creator":"Microsoft® Word 2016","Producer":"www.ilovepdf.com","CreationDate":"D:20230518204532+00'00'","ModDate":"D:20230518204534Z"},"metadata":null,"totalPages":7},"loc":{"pageNumber":1,"lines":{"from":22,"to":34}}}}],["7332abc0-a699-4b17-9a2e-04ea9156254d",{"pageContent":" Designed Technical Design Specifications and Mapping Documents with Transformation Rules. \n Strong knowledge on implementing SCD Type-1, Type-2 and Type-3 Dimensional tables and Facts. \n Having  Experience  in  Talend  Administration Center (Installation,  Deployment  and  Production \nsupport). \n Good Knowledge on TAC scheduling and deploying the jobs from Nexus, Creating the Execution \nplans for the Talend Jobs in TAC. \n Extensively involved in Performance Tuning, Unit Test Case and User Acceptance Test. \n Provided extensive support in production to troubleshoot and resolve the issues \n Having Experience in Healthcare solutions and different files (EDI, HL7). \n Understanding of a Cloud environment  ideally AWS and azure \n Experience working with version control tools such as GitHub, Bitbucket. \n Expertise in Building Complex Micro strategy, Power BI and Tableau reports for data analysis and \nforecasting needs.","metadata":{"source":"/tmp/resume-processor-NZq5ma/ETL_gc_PrudviRamireddy.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Author":"Prudvi Ramireddy","Creator":"Microsoft® Word 2016","Producer":"www.ilovepdf.com","CreationDate":"D:20230518204532+00'00'","ModDate":"D:20230518204534Z"},"metadata":null,"totalPages":7},"loc":{"pageNumber":1,"lines":{"from":33,"to":45}}}}],["05da9e80-b0db-43ac-b1bd-3502b2663b3c",{"pageContent":" Quick learner and excellent team player, ability to meet deadlines and work under Pressure. \n Ability to work in both team environment as well as Independent. \n worked in agile environment and using Atlassian tool set including JIRA, Confluence and Bitbucket. \n \n \nCERTIFICATION & ACHIEVEMENTS:                                                                                                                  \n \n• Certified Talend Data Integration v7 Certified Developer \n• Certificate of Appreciation Q4 FY23: PIRL Award  \n \nTECHNICAL SKILLS:                                                                                                                                               \n \n \nEDUCATION QUALIFICATION:                                                                                                                           \nGraduate from N.B.K.R. Institute of Science and Technology affiliated to S.V. University, A.P in 2012.","metadata":{"source":"/tmp/resume-processor-NZq5ma/ETL_gc_PrudviRamireddy.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Author":"Prudvi Ramireddy","Creator":"Microsoft® Word 2016","Producer":"www.ilovepdf.com","CreationDate":"D:20230518204532+00'00'","ModDate":"D:20230518204534Z"},"metadata":null,"totalPages":7},"loc":{"pageNumber":2,"lines":{"from":1,"to":15}}}}],["080c5c41-4c95-4abe-8edf-f884c7b94e51",{"pageContent":"Graduate from N.B.K.R. Institute of Science and Technology affiliated to S.V. University, A.P in 2012. \nORGANISATION DETAILS:                                                                                                                               \nVirtusa consulting services private Limited, Hyderabad      Aug 2021 to April 2023. \nRole: Consultant \n------------------------------------------------------------------------------------------------------------------------------------------ \nHawis Tech Solutions Pvt. Ltd., Hyderabad      Oct 2014 to Aug 2021. \nRole: Sr Software Engineer \n------------------------------------------------------------------------------------------------------------------------------------------ \nL&T HMRP Ltd., Hyderabad       July 2012 to Sept 2014. \nRole: Software Engineer \n------------------------------------------------------------------------------------------------------------------------------------------","metadata":{"source":"/tmp/resume-processor-NZq5ma/ETL_gc_PrudviRamireddy.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Author":"Prudvi Ramireddy","Creator":"Microsoft® Word 2016","Producer":"www.ilovepdf.com","CreationDate":"D:20230518204532+00'00'","ModDate":"D:20230518204534Z"},"metadata":null,"totalPages":7},"loc":{"pageNumber":2,"lines":{"from":15,"to":25}}}}],["1c420d82-5502-4eec-994c-eb40847c27d0",{"pageContent":"Role: Software Engineer \n------------------------------------------------------------------------------------------------------------------------------------------ \nWORK EXPERIENCE:                                                                                                                                       \n                   Aug 2021 to Till  \n  \n1. PROJECT:  S2S Recon (System to System Reconciliation)     \n   Client: Centene Corporation USA \n   Role: Talend Developer  \n    Team Size:14 members  \nETL Tools Talend(7.x/6.x/5.x Version) DI, DQ, Big Data, MDM, Informatica, AWS \nGlue and Azure Data Factory. \nITSM Tools BMC Remedy/Service Now \nLanguages       SQL, PL/SQL, T-SQL, C,C++,Java, Python \nOperating Systems      Windows NT/95/98/2000/XP, Linux & Unix \nXML Technologies HTML, DHTML, JavaScript,  \nScripting Language’s JavaScript, VB Script \nDatabases SQL Server 2000/2005/2008/2012, Oracle 8i/9i/10g/11g/12g, \nSnowflake, Azure Synapse, DB2, MySQL, Teradata, Redshift, Amazon","metadata":{"source":"/tmp/resume-processor-NZq5ma/ETL_gc_PrudviRamireddy.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Author":"Prudvi Ramireddy","Creator":"Microsoft® Word 2016","Producer":"www.ilovepdf.com","CreationDate":"D:20230518204532+00'00'","ModDate":"D:20230518204534Z"},"metadata":null,"totalPages":7},"loc":{"pageNumber":2,"lines":{"from":24,"to":41}}}}],["689fdd4b-1c2a-4004-98ca-28f8b3047f83",{"pageContent":"Scripting Language’s JavaScript, VB Script \nDatabases SQL Server 2000/2005/2008/2012, Oracle 8i/9i/10g/11g/12g, \nSnowflake, Azure Synapse, DB2, MySQL, Teradata, Redshift, Amazon \nS3, Oracle 11g, SQL server, MS SQL, PostgreSQL. \n \nWeb Servers                   Internet Information Server (IIS), Apache & Web Sphere \nReporting Tools           Micro strategy, Power BI, Tableau,  BMC Analytics, BMC Smart \nReporting, QlikView, Qlik Sense \nMethodologies Agile, Scrum, SDLC","metadata":{"source":"/tmp/resume-processor-NZq5ma/ETL_gc_PrudviRamireddy.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Author":"Prudvi Ramireddy","Creator":"Microsoft® Word 2016","Producer":"www.ilovepdf.com","CreationDate":"D:20230518204532+00'00'","ModDate":"D:20230518204534Z"},"metadata":null,"totalPages":7},"loc":{"pageNumber":2,"lines":{"from":39,"to":47}}}}],["69d1041c-08e6-4338-bd9d-6588ff9a0116",{"pageContent":"Project Description: Centene Corporation is a publicly traded and managed care company based in St. \nLouis, Missouri. It serves as an intermediary for government-sponsored and privately insured health care \nprograms. Centene ranked No. 24 on the 2021 Fortune 500 Centene was founded by Elizabeth Brinn as \nManaged Health Services, a nonprofit Medicaid plan in Milwaukee, Wisconsin in 1984.  \nCentene went public in December 2001. In 2006, the firm acquired US Scripte, a pharmacy benefits \nmanager. The company later merged US Script with subsidiaries to form its Envolve divisions. In 2011, \nthe firm formed Centurion, a provider of correctional health care services, as a joint venture with MHM \nServices. In 2018, it acquired MHM Services, including its stake in Centurion.  \nCentene began offering state-run Medicaid programs. Through Affordable Care Act exchanges in 2014.  \nOn July 2, 2015, Centene announced it would acquire Health Net. In March 2016, it finalized its","metadata":{"source":"/tmp/resume-processor-NZq5ma/ETL_gc_PrudviRamireddy.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Author":"Prudvi Ramireddy","Creator":"Microsoft® Word 2016","Producer":"www.ilovepdf.com","CreationDate":"D:20230518204532+00'00'","ModDate":"D:20230518204534Z"},"metadata":null,"totalPages":7},"loc":{"pageNumber":3,"lines":{"from":1,"to":10}}}}],["faf78361-fc6f-4481-ba9a-23115f29e925",{"pageContent":"Centene began offering state-run Medicaid programs. Through Affordable Care Act exchanges in 2014.  \nOn July 2, 2015, Centene announced it would acquire Health Net. In March 2016, it finalized its \nacquisition On September 12, 2017, it announced that it would acquire Fidelis Care, a nonprofit insurer \nin New York, for US$3.75 billion. In March 2019, it announced plans to acquire WellCare for US$17.3 \nbillion. On January 4, 2021, it was announced that it would acquire Magellan Health for $2.2 billion. On \nJanuary 4, 2022, the acquisition was completed.   \n Data reconciliation between 2 different systems as a Data hop in a Line of Business.  \n Part of this project worked on Medicaid, Market Place, Medicare, Centurion, ATC Line of \nBusinesses.  \n Data comparison for different hops like Softheon- UMV, UMV – Amisys, Amisys – RX, Amisys – \nEDW, UMV – EDW, &etc. \n \nRoles and Responsibilities: \n Design and development of Talend jobs as per the business rules.","metadata":{"source":"/tmp/resume-processor-NZq5ma/ETL_gc_PrudviRamireddy.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Author":"Prudvi Ramireddy","Creator":"Microsoft® Word 2016","Producer":"www.ilovepdf.com","CreationDate":"D:20230518204532+00'00'","ModDate":"D:20230518204534Z"},"metadata":null,"totalPages":7},"loc":{"pageNumber":3,"lines":{"from":9,"to":22}}}}],["9d176e69-d7b0-430a-9876-77f1162a1e81",{"pageContent":"EDW, UMV – EDW, &etc. \n \nRoles and Responsibilities: \n Design and development of Talend jobs as per the business rules. \n Imported data from Teradata and file like CSV, XLS, RPT and transformed and loaded into \nOracle. \n Comparison of two Data hop in landing Stage and Implementing Full load and CDC. \n Involved in complete Software Development Life Cycle (SDLC) process by analyzing business \nrequirements and understanding the functional workflow of information from source systems to \ndestination systems. \n Implementing SCD Type-1, Type-2 and Type-3 Dimensional tables and Facts. \n Developed procedures to populate the customer data warehouse with transaction data, cycle \nand monthly summary data, and historical data.  \n Performed data cleansing, enrichment, mapping tasks and automated data validation processes \nto ensure meaningful and accurate data was reported efficiently. \n Worked on the Teradata stored procedures and functions to confirm the data load it on the \ntable","metadata":{"source":"/tmp/resume-processor-NZq5ma/ETL_gc_PrudviRamireddy.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Author":"Prudvi Ramireddy","Creator":"Microsoft® Word 2016","Producer":"www.ilovepdf.com","CreationDate":"D:20230518204532+00'00'","ModDate":"D:20230518204534Z"},"metadata":null,"totalPages":7},"loc":{"pageNumber":3,"lines":{"from":19,"to":35}}}}],["ccc3724d-84e4-47a9-905b-6e85ee9ab19b",{"pageContent":"to ensure meaningful and accurate data was reported efficiently. \n Worked on the Teradata stored procedures and functions to confirm the data load it on the \ntable \n Running sub jobs in parallel, used parallelize component and multi thread execution. \n Perform code testing in Dev, SIT, UAT and regression environments \n Extensively worked with tMap, tParallelize, tJava, tAggregateRow, tDBOutputBulkExec, , \ntRunJob,tSystem, tsendmail, tLogCatche tStatCatcher, tDie and Used file components like \ntFilelist,tFilecopy,tFileDelete. \n Involved in code migration from Development to Test and Test to Production environments  \n Responsible to work with the Business team on any issues and obtaining the UAT’s.  \n Done the Unit testing and UAT for the developed jobs. \n Publishing jobs to GIT and deploying them to TAC and monitoring issues. \n Deploy and executed jobs in Control-M. \n Provided extensive support in production to troubleshoot and resolve the issues.","metadata":{"source":"/tmp/resume-processor-NZq5ma/ETL_gc_PrudviRamireddy.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Author":"Prudvi Ramireddy","Creator":"Microsoft® Word 2016","Producer":"www.ilovepdf.com","CreationDate":"D:20230518204532+00'00'","ModDate":"D:20230518204534Z"},"metadata":null,"totalPages":7},"loc":{"pageNumber":3,"lines":{"from":33,"to":46}}}}],["624c2d33-b15b-4a90-9bc4-da29a5f0c5be",{"pageContent":" Deploy and executed jobs in Control-M. \n Provided extensive support in production to troubleshoot and resolve the issues. \n \nEnvironment : Talend 7.1 & 7.3, TAC, Teradata, Oracle, My SQL, MS SQL, Micro Strategy, Flat Files, \nGIT, JIRA, Control-M.                   \n------------------------------------------------------------------------------------------------------------------------------------------ \n          Sept 2019 to July 2021","metadata":{"source":"/tmp/resume-processor-NZq5ma/ETL_gc_PrudviRamireddy.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Author":"Prudvi Ramireddy","Creator":"Microsoft® Word 2016","Producer":"www.ilovepdf.com","CreationDate":"D:20230518204532+00'00'","ModDate":"D:20230518204534Z"},"metadata":null,"totalPages":7},"loc":{"pageNumber":3,"lines":{"from":45,"to":51}}}}],["8401b309-a818-4049-ac38-89762311424b",{"pageContent":"2. PROJECT:  PDB EDH(PETRONAS Dagangan Berhad Enterprise Data Hub)     \n  Client: Petronas  Malaysia \n  Role : Sr Software Engineer- Talend Developer  \n    Team Size:12 members  \n \nProject Description: Petroliam Nasional Berhad (National Petroleum Limited), commonly known \nas Petronas, is a Malaysian oil and gas company. Established in 1974 and wholly owned by the \nGovernment of Malaysia, the corporation is vested with the entire oil and gas resources in Malaysia and \nis entrusted with the responsibility of developing and adding value to these resources. Petronas is \nranked among Fortune Global 500's largest corporations in the world. In the 2017 Forbes Global 2000, \nPetronas Gas was ranked as the 1881st largest public company in the world.  \n PDB EDH(PETRONAS Dagangan Berhad Enterprise Data Hub) Is a transformational program aimed at \ncreating a unified, advanced analytics solution for reporting data. Source is file like .txt, .csv and .xml it is","metadata":{"source":"/tmp/resume-processor-NZq5ma/ETL_gc_PrudviRamireddy.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Author":"Prudvi Ramireddy","Creator":"Microsoft® Word 2016","Producer":"www.ilovepdf.com","CreationDate":"D:20230518204532+00'00'","ModDate":"D:20230518204534Z"},"metadata":null,"totalPages":7},"loc":{"pageNumber":4,"lines":{"from":2,"to":14}}}}],["f16c3bfd-fcfa-48c8-8d7f-a4e66dbfdb9b",{"pageContent":"creating a unified, advanced analytics solution for reporting data. Source is file like .txt, .csv and .xml it is \ndump into Amazon S3 Bucket from SQL DB. Designed and developed jobs, applying transformations and \nload into Azure SQL \n \nRoles and Responsibilities: \n Review of business requirements \n Prepare technical design documents \n Developed Talend DI jobs, big data jobs and pig scripts for every source system. \n Data integration platforms used to generate/develop the transformations or Validations or \nbusiness logics to ensure consent of data with requirements.  \n Developed shell scripts to process in the Data pipeline. \n Created Data pipelines of AWS. \n Imported file from Amazon S3 Bucket using ts3get, ts3put and transformed. \n Implementing SCD Type-1, Type-2 and Type-3 Dimensional tables and Facts. \n Running sub jobs in parallel, used parallelize component and multi thread execution.","metadata":{"source":"/tmp/resume-processor-NZq5ma/ETL_gc_PrudviRamireddy.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Author":"Prudvi Ramireddy","Creator":"Microsoft® Word 2016","Producer":"www.ilovepdf.com","CreationDate":"D:20230518204532+00'00'","ModDate":"D:20230518204534Z"},"metadata":null,"totalPages":7},"loc":{"pageNumber":4,"lines":{"from":14,"to":28}}}}],["c4bf7f0e-acac-476d-9475-bda342ecc0aa",{"pageContent":" Implementing SCD Type-1, Type-2 and Type-3 Dimensional tables and Facts. \n Running sub jobs in parallel, used parallelize component and multi thread execution. \n Extensively worked with tMap, tParallelize, tJava, tAggregateRow, tDBOutputBulkExec, \ntRunJob,tSystem, tsendmail, tLogCatche tStatCatcher, tDie and Used file components like \ntFilelist,tFilecopy,tFileDelete.  \n Responsible to work with the Business team on any issues and obtaining the UAT’s.  \n Done the Unit testing and UAT for the developed jobs. \n Publishing jobs to Nexus and deploying them to TAC and monitoring issues \n \nEnvironment : Talend 7.1 & 7.2., TAC, My SQL, MS SQL, S/4HANA, Redshift, Azure SQL, Amazon S3, \nFlat Files, Tableau, GIT, Nexus. \n \n------------------------------------------------------------------------------------------------------------------------------------------ \n \n                        Feb 2017 to Aug 2019. \n3. PROJECT: Global EDH (Global Enterprise Data Hub)","metadata":{"source":"/tmp/resume-processor-NZq5ma/ETL_gc_PrudviRamireddy.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Author":"Prudvi Ramireddy","Creator":"Microsoft® Word 2016","Producer":"www.ilovepdf.com","CreationDate":"D:20230518204532+00'00'","ModDate":"D:20230518204534Z"},"metadata":null,"totalPages":7},"loc":{"pageNumber":4,"lines":{"from":27,"to":42}}}}],["3061ff0e-9538-4cbc-a1dd-1d61dc3465b3",{"pageContent":"Feb 2017 to Aug 2019. \n3. PROJECT: Global EDH (Global Enterprise Data Hub)       \n   Client: Budweiser, USA  \n   Role: Sr Software Engineer -Talend Developer and Production Support \n   Team size: 10members \n    \nProject Descriptions: Budweiser is an American-style pale lager produced by Anheuser-Busch, part of AB \nInBev. Introduced in 1876 by Carl Conrad & Co. of St. Louis, Missouri. Budweiser has become one of the \nlargest-selling beers in the United States. \nGlobal EDH (Global Enterprise Data Hub) is a transformational program aimed at creating a \nunified, advanced analytics solution for reporting data. Global EDH contributes to Facilitate \nbetter decision making with the most accurate, timely and relevant data. The program builds","metadata":{"source":"/tmp/resume-processor-NZq5ma/ETL_gc_PrudviRamireddy.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Author":"Prudvi Ramireddy","Creator":"Microsoft® Word 2016","Producer":"www.ilovepdf.com","CreationDate":"D:20230518204532+00'00'","ModDate":"D:20230518204534Z"},"metadata":null,"totalPages":7},"loc":{"pageNumber":4,"lines":{"from":41,"to":52}}}}],["7fae68d8-8824-45d7-838c-f23129c87e94",{"pageContent":"onto Ab-Inbev existing architecture and initially includes Sales, Finance, Services, Supply Chain \nand IT.  \n \nRoles and Responsibilities:  \n• Involved in the Data lake Technical Architecture design.   \n• Coordinating with client business team and collecting the requirements. \n• Preparing Technical Specifications as per the client’s requirement. \n• Developed Talend DI jobs, big data jobs for every source system (sales force, zuora, \nsqlserver etc.). \n• Worked on hive table’s creation and loading using Talend. \n• Working on Exception Handling. \n• Performing transformation and filtering data as per the client requirement \n• Worked on data cleansing and standardization using the cleanse functions \n• Experience in working with Hdfs, Sqoop and Hive components \n• Experience in working with Amazon S3, Redshift & Azure blob components \n• Expertise in analyzing the data issues and code bugs. \n• Perform validation check, Unit testing, Integration, and performance testing","metadata":{"source":"/tmp/resume-processor-NZq5ma/ETL_gc_PrudviRamireddy.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Author":"Prudvi Ramireddy","Creator":"Microsoft® Word 2016","Producer":"www.ilovepdf.com","CreationDate":"D:20230518204532+00'00'","ModDate":"D:20230518204534Z"},"metadata":null,"totalPages":7},"loc":{"pageNumber":5,"lines":{"from":1,"to":17}}}}],["b6ec5e7f-4598-4c9e-83d9-7126809eb0ba",{"pageContent":"• Expertise in analyzing the data issues and code bugs. \n• Perform validation check, Unit testing, Integration, and performance testing \n• Perform deployment and execution on TAC & Talend Cloud in client’s Environment \n \nEnvironment : Talend DI and BigData, Oracle, Redshift, Azure blob, GIT, JIRA, MySQL, CSV files, sales \nforce, zuora, Power BI, Talend Administration Centre (TAC). \n------------------------------------------------------------------------------------------------------------------------------------------ \n \n        April 2016 to Jan 2017. \n4. PROJECT: IMCM (Integrated Multi-Channel Marketing)       \n   Client: Bayer, UK \n   Role: Software Engineer- Talend Developer \n   Team size: 8members \n \nProject Descriptions: Bayer AG is a German multinational pharmaceutical and life sciences company and \none of the largest pharmaceutical companies in the world. Headquartered in Leverkusen, Bayer's areas","metadata":{"source":"/tmp/resume-processor-NZq5ma/ETL_gc_PrudviRamireddy.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Author":"Prudvi Ramireddy","Creator":"Microsoft® Word 2016","Producer":"www.ilovepdf.com","CreationDate":"D:20230518204532+00'00'","ModDate":"D:20230518204534Z"},"metadata":null,"totalPages":7},"loc":{"pageNumber":5,"lines":{"from":16,"to":31}}}}],["14c13b0b-2fb8-4af0-a67a-8f484f493e5c",{"pageContent":"one of the largest pharmaceutical companies in the world. Headquartered in Leverkusen, Bayer's areas \nof business include pharmaceuticals; consumer healthcare products, agricultural chemicals, seeds and \nbiotechnology products. The company is a component of the Euro Stoxx 50 stock market index.  \nBayer was founded in 1863 in Barmen as a partnership between dye salesman Friedrich Bayer and dyer \nFriedrich Weskott. In 1899 Bayer launched the compound acetylsalicylic acid under the trademarked \nname Aspirin. In 1904 Bayer received a trademark for the \"Bayer Cross\" logo, which was subsequently \nstamped onto each aspirin tablet, creating an iconic product that is still sold by Bayer. Other commonly \nknown products initially commercialized by Bayer include heroin, phenobarbital, polyurethanes, \nand polycarbonates. \n Bayer UK is a leader in pharmaceuticals, consumer health and crop science. With our innovative and","metadata":{"source":"/tmp/resume-processor-NZq5ma/ETL_gc_PrudviRamireddy.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Author":"Prudvi Ramireddy","Creator":"Microsoft® Word 2016","Producer":"www.ilovepdf.com","CreationDate":"D:20230518204532+00'00'","ModDate":"D:20230518204534Z"},"metadata":null,"totalPages":7},"loc":{"pageNumber":5,"lines":{"from":31,"to":40}}}}],["a25d1036-00aa-45a7-8ac6-b67013cede2d",{"pageContent":"and polycarbonates. \n Bayer UK is a leader in pharmaceuticals, consumer health and crop science. With our innovative and \nsustainable products, we are contributing to finding solutions to some of the major challenges of our \ntime. \nWe bring together our people, partners and customers, placing innovation, sustainability and digital \ntransformation at the heart of everything we do. Our products and solutions help us to deliver our vision \nof 'health for all, hunger for none' by: \n IMCM will provide consolidated Marketing details to Bayer. \n This application gathers different channels marketing information like fact call, emails, \nAdvertising. \n Data will be extracted from SQL server and loading into Redshift after transformations. \n Applied slowly changing dimension Type2.","metadata":{"source":"/tmp/resume-processor-NZq5ma/ETL_gc_PrudviRamireddy.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Author":"Prudvi Ramireddy","Creator":"Microsoft® Word 2016","Producer":"www.ilovepdf.com","CreationDate":"D:20230518204532+00'00'","ModDate":"D:20230518204534Z"},"metadata":null,"totalPages":7},"loc":{"pageNumber":5,"lines":{"from":39,"to":50}}}}],["ddf4c4b8-209e-4036-9684-a46658076d17",{"pageContent":"Roles and Responsibilities:  \n Analysis of business requirement, prepared source to target ETL mappings. \n Done the client demos for the application and gathered additional requirements required. \n Design and development of Talend jobs as per the business rules. \n Unit testing along with UTP & UTR documented. \n Code move to QA and Production environment. \n Deployment and scheduling of jobs in TAC server. \n Involved in UAT testing and bug fixing. \n Additionally, involved in code reviews. \nEnvironment :  Talend 6.4, MySQL, SQL server, BMC Smart Reporting, AWS S3 & Redshift. \n------------------------------------------------------------------------------------------------------------------------------------------ \n         Oct 2014 to March 2016. \n5. PROJECT: Insurance Information system \n    Client: Guardian Life Insurance Company, USA \n    Role: Software Engineer \n    Team Size: 10members","metadata":{"source":"/tmp/resume-processor-NZq5ma/ETL_gc_PrudviRamireddy.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Author":"Prudvi Ramireddy","Creator":"Microsoft® Word 2016","Producer":"www.ilovepdf.com","CreationDate":"D:20230518204532+00'00'","ModDate":"D:20230518204534Z"},"metadata":null,"totalPages":7},"loc":{"pageNumber":6,"lines":{"from":2,"to":17}}}}],["0f886997-c937-40b8-b3fd-e24ac13b473f",{"pageContent":"Oct 2014 to March 2016. \n5. PROJECT: Insurance Information system \n    Client: Guardian Life Insurance Company, USA \n    Role: Software Engineer \n    Team Size: 10members \n \nProject Description: Insurance is the Fourth Largest Mutual Life Insurance Company located in New \nYork, USA. Founded in 1860, it is now a Fortune 300 company. With over 120,000 group plans in force, \nGuardian Company and its subsidiaries today provide almost six million people with life and disability \nIncome insurance, retirement services, and investment products. Creation of IIS data mart is to \nautomate the report generation process is proposed by Guardian Life Insurance Company. The data \nmart would store data consolidated from source systems, Data is to be extracted every night and loaded \ninto the data mart. Talend is used for data extraction and loading. This system is used to perform Policy \nformulating, Claim processing. \n \nRoles and Responsibilities: \n Worked with client on requirements.","metadata":{"source":"/tmp/resume-processor-NZq5ma/ETL_gc_PrudviRamireddy.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Author":"Prudvi Ramireddy","Creator":"Microsoft® Word 2016","Producer":"www.ilovepdf.com","CreationDate":"D:20230518204532+00'00'","ModDate":"D:20230518204534Z"},"metadata":null,"totalPages":7},"loc":{"pageNumber":6,"lines":{"from":13,"to":29}}}}],["ba5c4009-b99f-4dc3-a294-fa3233e48866",{"pageContent":"formulating, Claim processing. \n \nRoles and Responsibilities: \n Worked with client on requirements. \n Worked closely with business analyst to understand the data model and business. \n Designed Talend ETL jobs to fetch the data from various sources like flat files, MS SQL and \nOracle databases and to load the data into databases like Oracle and MS SQL. \n Developed mapping to load the data in slowly changing dimension. \n Implemented Error Handling to provide the detailed error messages. Experienced on processing \nthe data files through Talend Data Integration. \n Prepare metadata in Talend Integration studio repository. \n Extensively used database connections, file component, tmap, tAggregator etc. \n Imported data from various Sources transformed and loaded into Staging Area. \n Worked on processing the data files through Talend Data Integration. \n Imported data from various Sources transformed and loaded into Staging Area.","metadata":{"source":"/tmp/resume-processor-NZq5ma/ETL_gc_PrudviRamireddy.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Author":"Prudvi Ramireddy","Creator":"Microsoft® Word 2016","Producer":"www.ilovepdf.com","CreationDate":"D:20230518204532+00'00'","ModDate":"D:20230518204534Z"},"metadata":null,"totalPages":7},"loc":{"pageNumber":6,"lines":{"from":26,"to":40}}}}],["be0c56da-38ed-4cd9-94f6-501fb12367f9",{"pageContent":" Worked on processing the data files through Talend Data Integration. \n Imported data from various Sources transformed and loaded into Staging Area. \n  \nEnvironment : Talend Data Integration 5.6, SQL Server, FTP, Rest API, Control-M,     \n                          Rally, GIT, QlikView. \n------------------------------------------------------------------------------------------------------------------------------------------","metadata":{"source":"/tmp/resume-processor-NZq5ma/ETL_gc_PrudviRamireddy.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Author":"Prudvi Ramireddy","Creator":"Microsoft® Word 2016","Producer":"www.ilovepdf.com","CreationDate":"D:20230518204532+00'00'","ModDate":"D:20230518204534Z"},"metadata":null,"totalPages":7},"loc":{"pageNumber":6,"lines":{"from":39,"to":44}}}}],["fd8ca3a6-cae4-420e-a529-17caa4bf6a2f",{"pageContent":"July 2012 to Sept 2014. \n \n6. PROJECT: HMRL \n    Client: L&T HMRL, Hyderabad \n    Role: Software Engineer \n    Team Size: 4members \n            \nRoles and Responsibilities:  \n• Involved in deployment activities related to QA and Production. \n• Hands on Experience on TAC (Talend Administrator Center) related activity such as \nScheduling and monitoring of Talend jobs. \n• Application Support, Maintenance and Enhancement services for Enterprise Data \nOperations. \n• Good in handling of incidents, service requests and change requests. \n• Expertise in analyzing the data issues and code bugs. \n• Preparing weakly reports based on client request. \n• Continuously Monitoring the jobs and Execution plan’s in TAC. \nEnvironment : Talend DI 5.1.1& 5.4.1, MSsql, SVN, MySQL, CSV files,  \n   Talend Administration Centre (TAC).","metadata":{"source":"/tmp/resume-processor-NZq5ma/ETL_gc_PrudviRamireddy.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Author":"Prudvi Ramireddy","Creator":"Microsoft® Word 2016","Producer":"www.ilovepdf.com","CreationDate":"D:20230518204532+00'00'","ModDate":"D:20230518204534Z"},"metadata":null,"totalPages":7},"loc":{"pageNumber":7,"lines":{"from":6,"to":24}}}}]],{"0":"8df23e61-596f-4303-95cf-89a06a20fa17","1":"f11c961b-af4e-419f-8230-f3a229a7042d","2":"3ea54c97-10c6-4532-9711-c525e4dd3aae","3":"7332abc0-a699-4b17-9a2e-04ea9156254d","4":"05da9e80-b0db-43ac-b1bd-3502b2663b3c","5":"080c5c41-4c95-4abe-8edf-f884c7b94e51","6":"1c420d82-5502-4eec-994c-eb40847c27d0","7":"689fdd4b-1c2a-4004-98ca-28f8b3047f83","8":"69d1041c-08e6-4338-bd9d-6588ff9a0116","9":"faf78361-fc6f-4481-ba9a-23115f29e925","10":"9d176e69-d7b0-430a-9876-77f1162a1e81","11":"ccc3724d-84e4-47a9-905b-6e85ee9ab19b","12":"624c2d33-b15b-4a90-9bc4-da29a5f0c5be","13":"8401b309-a818-4049-ac38-89762311424b","14":"f16c3bfd-fcfa-48c8-8d7f-a4e66dbfdb9b","15":"c4bf7f0e-acac-476d-9475-bda342ecc0aa","16":"3061ff0e-9538-4cbc-a1dd-1d61dc3465b3","17":"7fae68d8-8824-45d7-838c-f23129c87e94","18":"b6ec5e7f-4598-4c9e-83d9-7126809eb0ba","19":"14c13b0b-2fb8-4af0-a67a-8f484f493e5c","20":"a25d1036-00aa-45a7-8ac6-b67013cede2d","21":"ddf4c4b8-209e-4036-9684-a46658076d17","22":"0f886997-c937-40b8-b3fd-e24ac13b473f","23":"ba5c4009-b99f-4dc3-a294-fa3233e48866","24":"be0c56da-38ed-4cd9-94f6-501fb12367f9","25":"fd8ca3a6-cae4-420e-a529-17caa4bf6a2f"}]