[[["229a6e42-2a3a-41bc-bd02-26f25eec13ac",{"pageContent":"RajuN\nPhone:860-248-9503\n♦\nnune2642@gmail.com\nSeniorDataAnalyst\nExpertiseinDataWarehousingandBigDatadevelopmentlifecycle\nSummary:Over12+yearsofITexperienceinAnalysis,design,testingandImplementationofBusiness\nIntelligencesolutionsusingDataWarehouse/DataMartDesign,ETL,OLAP,Client/Serverapplications.\nExperiencedinallphasesofrequirementsinend-to-endtasksindifferentSDLCAGILE,IterativeandWaterfall\nforprojecttestingmethodologies.\nTenPlus(12+)Yearsofhands-onexperienceinOracleandPL/SQLwritingStoredProcedures,,triggers,\nviews,materializedviews.\nNinePlus(10+)GoodunderstandingofDataWarehouse/Datamartconcepts,OLAP&OLTPsystemsfrom\ndesignandanalysistoimplementation.\nNinePlus(10+)yearsofexperienceinDataAcquisition,MasterDataManagement,DataAnalysis,Business\nIntelligence&DataArchitecture.\nNinePlus(10+)Yearsofexperienceindatawarehousingapplicationsincludinganalysis,architecture,design,\ndevelopment&supportusingInformaticaPowerCenter,Linux,Databricks,Python.","metadata":{"source":"/tmp/resume-processor-sLMqmq/Raju_N_DA.DOCX.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Copy of Raju_N_DA.DOCX","Producer":"Skia/PDF m122 Google Docs Renderer"},"metadata":null,"totalPages":8},"loc":{"pageNumber":1,"lines":{"from":1,"to":18}}}}],["996da698-6316-4073-b2f3-37dc7b4bfcd5",{"pageContent":"NinePlus(10+)Yearsofexperienceindatawarehousingapplicationsincludinganalysis,architecture,design,\ndevelopment&supportusingInformaticaPowerCenter,Linux,Databricks,Python.\nExtensiveexperienceondevelopingETLcodeinInformaticaPowerCenterusingcomponentssuchas\nPowerCenterDesigner,PowerCenterRepositoryManager,WorkflowManagerandmonitoringand\ntroubleshootingusingWorkflowMonitor.IBMDataStage9/8.1,SSIS.\nLeverageabroadstackoftechnologies—Python,Docker,AWS,Airflow,andSparktorevealtheinsights\nhiddenwithinhugevolumesofnumericandtextualdata\nSixPlus(6+)YearsofexperiencewithNoSQLdatabases(MongoDB,Cassandra)andHadoopbigdata\necosystem(HDFS,MapReduce,Hive,Spark,Impala,)\nExperience&Achievements\nOptum(UHG),MN(Remote.)February2023–TillDate\nSr.SystemAnalyst(ETL//BIGData/AWS)\nResponsibilities:\n▪DevelopedTestPlan,TestCases,Scenarios,TestData&TestStrategydocumentsbasedonBRD\nmappedtoTestScriptstoensureanyChangeControlinrequirementsleadstotestcaseupdate.","metadata":{"source":"/tmp/resume-processor-sLMqmq/Raju_N_DA.DOCX.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Copy of Raju_N_DA.DOCX","Producer":"Skia/PDF m122 Google Docs Renderer"},"metadata":null,"totalPages":8},"loc":{"pageNumber":1,"lines":{"from":17,"to":31}}}}],["ddcaf3f4-dffb-4b3b-b343-acd42b4793c4",{"pageContent":"Responsibilities:\n▪DevelopedTestPlan,TestCases,Scenarios,TestData&TestStrategydocumentsbasedonBRD\nmappedtoTestScriptstoensureanyChangeControlinrequirementsleadstotestcaseupdate.\n \n▪DevelopedcomplexSQLScriptstovalidatetheCompleteness,Correctness,IntegrityandAccuracy\nofDataloadedintotargetdatabaseaccordingtotheBRDwithinanETLprocesstestingcycle.\n \n▪CompleteresponsibleforQAdeliverablesthatincludesCode/Datamigrationandmaintainingallthe\ntestcasesanddefectsinHPQCALMforalltheprojectsfromQAstand-point.\n \n▪Responsibleforanalyzingnewdatasources(KaRka,RDBMS,logetc.)andbringindataintotarget\nsysteminnearreal-time.\n \n▪AnalyzeandcleanserawdatausingHiveQL\n \n▪ExperienceindatatransformationsusingMap-Reduce,andHIVEfordifferentRileformats.\n \n▪InvolvedinconvertingHive/SQLqueriesintotransformationsusingPython.\n \n▪Performedcomplexjoinsontablesinahivewithvariousoptimizationtechniques\n \n▪CreatedHivetablesasperrequirements,internalorexternaltablesdeRinedwithappropriatestatic\nand","metadata":{"source":"/tmp/resume-processor-sLMqmq/Raju_N_DA.DOCX.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Copy of Raju_N_DA.DOCX","Producer":"Skia/PDF m122 Google Docs Renderer"},"metadata":null,"totalPages":8},"loc":{"pageNumber":1,"lines":{"from":29,"to":51}}}}],["6129c1f7-409a-46f2-b9aa-c72d59900bdd",{"pageContent":"▪Performedcomplexjoinsontablesinahivewithvariousoptimizationtechniques\n \n▪CreatedHivetablesasperrequirements,internalorexternaltablesdeRinedwithappropriatestatic\nand\ndynamicpartitions,intendedforefRiciency.\n \n▪WorkedonBuildingpartoforacledatabaseinRedshift.","metadata":{"source":"/tmp/resume-processor-sLMqmq/Raju_N_DA.DOCX.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Copy of Raju_N_DA.DOCX","Producer":"Skia/PDF m122 Google Docs Renderer"},"metadata":null,"totalPages":8},"loc":{"pageNumber":1,"lines":{"from":48,"to":54}}}}],["c1dd0b04-d0aa-43b3-a704-05b5f077dfcf",{"pageContent":"▪WroteLinux/DatabricksforimportingandexportingdatafromRDBMStoHDFS.\n \n▪WorkedextensivelywithHIVEDDLSandHiveQuerylanguage(HQL)\n \n▪InvolvedinloadingdatafromtheedgenodetoHDFSusingshellscripting.\n \n▪Hands-onexperienceonworkingwithAWSserviceslikeLambdafunction,Athena,DynamoDB,Step\nfunctions,SNS,\n \n▪SQS,S3,IAMetc.\n \n▪ExperienceinbuildingpowerbireportsonAzureAnalysisservicesforbetterperformancewhen\ncomparingthatto\n \n▪CreatedandmaintainedtechnicaldocumentationforlaunchingtheHadoopclusterandforexecuting\nHivequeries.\n \n▪BuildIntegrationbetweenapplicationsprimarilySalesforce.\n \n▪conRigurations,Real-Timeappslikeprocessdesignerandprocessdeveloper.\n \n▪CarriedoutdatatransformationandcleansingusingSQLqueriesandPySpark.\n \n▪WorkextensivelywithRlatRiles.Loadingthemintoon-premiseapplicationsandretrievingdatafrom\napplicationstoRiles.\n \n▪WriteSQLqueriesandcreatetestdatainsalesforceforDatabrickscloudmappingsunittesting.\n \n▪PrepareTDDs,TestCasedocumentsaftereachprocesshasbeendeveloped.","metadata":{"source":"/tmp/resume-processor-sLMqmq/Raju_N_DA.DOCX.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Copy of Raju_N_DA.DOCX","Producer":"Skia/PDF m122 Google Docs Renderer"},"metadata":null,"totalPages":8},"loc":{"pageNumber":2,"lines":{"from":2,"to":30}}}}],["6deaf8c7-bffe-4dde-a9a4-184a3c644739",{"pageContent":"applicationstoRiles.\n \n▪WriteSQLqueriesandcreatetestdatainsalesforceforDatabrickscloudmappingsunittesting.\n \n▪PrepareTDDs,TestCasedocumentsaftereachprocesshasbeendeveloped.\n \n▪Identifyandvalidatedatabetweensourceandtargetapplications.\n \n▪Verifydataconsistencybetweensystems.\n \n▪Wasresponsibleforcreatingon-demandtablesonS3RilesusingLambdaFunctionsandAWSGlue\nusing\nPythonandSpark.\n \n▪CoordinatedwiththeteamandDevelopedaframeworktogenerateDailyadhoc,reports,and\nextracts\nfromenterprisedataandautomatedusingDatabricksJobScheduler.\n \n▪DesignedandCo-ordinatedwiththeDataScienceteaminimplementingAdvancedAnalyticalModels\nin\nHadoopClusteroverlargeDatasets.\n \n▪Createdmonitors,alarms,notiRicationsandlogsforLambdafunctions,GlueJobs,andEC2hosts\nusing\nCloudwatch\n \n▪UsedAWSGlueforthedatatransformation,validationanddatacleansing.\n \n▪UsedPythonBoto3toconRiguretheservicesAWSglue,EC2,S3.\n \n▪Buildnear-real-timepipelinesbyconsumingdatafromKaRkaandtoloaddataintoAWSCloudData\nLake.","metadata":{"source":"/tmp/resume-processor-sLMqmq/Raju_N_DA.DOCX.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Copy of Raju_N_DA.DOCX","Producer":"Skia/PDF m122 Google Docs Renderer"},"metadata":null,"totalPages":8},"loc":{"pageNumber":2,"lines":{"from":26,"to":57}}}}],["9c47c8d5-6fe6-4d35-8b61-ad8cdd61f4cb",{"pageContent":"▪UsedPythonBoto3toconRiguretheservicesAWSglue,EC2,S3.\n \n▪Buildnear-real-timepipelinesbyconsumingdatafromKaRkaandtoloaddataintoAWSCloudData\nLake.\n \n▪WorkingexperienceonJIRAtocommunicateProjectManagementalldefectsraisedduringtest\ncycles.\n \n▪WorkingexperienceonagilemodelanddailyScrumStand-upsforQAupdatesanddefectstatus.\n \n▪ExperiencedonDefectmanagementlifecycle&raisedthedefectsbasedonprioritylevelinHPALM\nEnvironment:HPALM,Jira,Azure,Databricks,Erwin,RDBMS,Hadoop,HDFS,Hive,PIG,Cloudera,\nMapReduce,Python,AWS,Unixscripts,FlatFiles,XMLRilesMachineLearning-Algorithms,KaRka,\nOffsetExplorer\nCMS/NPSS,Columbia,WAJuly2017–current\nSystemsDATAANALYST\nEnvironment:MDM,AWS-Cloud,EMR,Pyspark,DMExpress,Informatica,DB2,Linux,Unix,Shell,Scripting,\nPythonPandas,Databricks,Qubole,Jira,Data-Frames,HiveMetastore,Teradata14,PL/SQL,Eclipse,Java,\nDataStudio,JupyterAnaconda3,SoapUI,MicroStrategy,Mobaxterm,Winmerge,JMeter","metadata":{"source":"/tmp/resume-processor-sLMqmq/Raju_N_DA.DOCX.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Copy of Raju_N_DA.DOCX","Producer":"Skia/PDF m122 Google Docs Renderer"},"metadata":null,"totalPages":8},"loc":{"pageNumber":2,"lines":{"from":54,"to":72}}}}],["2a361f05-262f-4939-acc3-22bc09097583",{"pageContent":"Kroger,Cincinnati,Ohio(October2015–Jun\n2017)\nNGLSr.DataAnalyst\n•DevelopedMapping’sinAginityManagementworkbenchforloadingdataintocorresponding\nsources\n•DevelopedAttributesinAttriubteworkbenchforloadingthedatausingMappingrules\n•PublishedusingPublicationwizardofAginityAmpthedatatotestthedataagainstTables\npresentinstaging\n•PerformedFunctionalTestingandBack-endTestingusingthedatabasecomparableresults.\n•Created,Loadnewormodifieddataintoback-endNetezzadatabase.\n•InvolvedindoubleprogrammingandQCcheckoftheprogramswrittenbyfellowprogrammers.\n•CreatedTables,GraphsandListingsforclinicalstudy.\n•ExtensivelyusedSQLprogramminginbackendandfront-endfunctions,procedures,packagesto\nimplementbusinessrulesandsecurity\n•CreatedIBMUnicaCampaignsflatfilesforprovidingtothevendorfortherecampaign\ngeneration\n•CreatedTivolijobs,JobStream&RanthemfororchestrationofdataloadsusingShellscript\n•DevelopedjsonfilethatcreatessqlfileswhichloadsdatabyusingthesqlgeneratedbyAginity\nAMP","metadata":{"source":"/tmp/resume-processor-sLMqmq/Raju_N_DA.DOCX.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Copy of Raju_N_DA.DOCX","Producer":"Skia/PDF m122 Google Docs Renderer"},"metadata":null,"totalPages":8},"loc":{"pageNumber":3,"lines":{"from":1,"to":19}}}}],["6db89950-ea08-4cc8-b381-6798caf59b6c",{"pageContent":"generation\n•CreatedTivolijobs,JobStream&RanthemfororchestrationofdataloadsusingShellscript\n•DevelopedjsonfilethatcreatessqlfileswhichloadsdatabyusingthesqlgeneratedbyAginity\nAMP\n•DevelopedshellScripttoloadtextfilespresentinunixboxintocorrespondingdatabase\n•DevelopedCognosreportsaspertheOrganizationstandardsandtestedthem\n•DevelopedtableaureportstoensureavailabilityofCampaigningdatatomeettheNeedsofIBM\nUnicaCampaign\n•DevelopedshellscriptthatloadsintoNetezzatablespresentusingpublicationpresentinAginity\nAMP\n•Designed&CreatedMappingdocumentsbasedontheBusinessrequirements(Alsoreferred\nSourcetoTargetDetailedmappingdocument&Transformationrulesdocument).\n•InvolvedinthepreparationofTestStrategy&TestCases\n•DevelopedandPerformedexecutionofTestScriptstoshowhowmanyrecordsarepassedorfail\n•LoadeddataintonetezzatablesfromvariousdatasourceslikeNetezza,SQLServer,Oracle,flat\nfilesbycreatingInformaticaMappings\n•AssistedincreatingfactanddimensiontableimplementationinStarSchemamodelbasedon\nrequirements.","metadata":{"source":"/tmp/resume-processor-sLMqmq/Raju_N_DA.DOCX.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Copy of Raju_N_DA.DOCX","Producer":"Skia/PDF m122 Google Docs Renderer"},"metadata":null,"totalPages":8},"loc":{"pageNumber":3,"lines":{"from":16,"to":33}}}}],["bec1c0ff-ce4a-49f9-be37-babc7392ece9",{"pageContent":"filesbycreatingInformaticaMappings\n•AssistedincreatingfactanddimensiontableimplementationinStarSchemamodelbasedon\nrequirements.\n•CreatedETLtestdataforallETLmappingrulestotestthefunctionalitydata\n•WrotecomplexSQLscriptsusinginnerjoins,Crossjoinsandouterjoinsandsubqueries\n•CreateTestscriptsbyusingT-SQL.Programmingelementsincludecontrol-of-flowtechniques,\nlocalandglobalvariables,functions,anderrorhandlingtechniques\n•Participatedinthereleasecontrolprocess(whentheapplicationistransferredfromthebuildteam\ntothetestteam)toensurethatsolutionsmeetbusinessrequirements\n•ParticipatedinthePIPlanning:QuantitativeMetrics(togetanideaofthebusinessvaluegained\nduringPrviousPI)\n•SprintDemowithBussinessUsers(Ademotorevieweverythingcompletedduringthesprint)\n•ExtensivelyexecutedT-SQLqueriesinordertoviewsuccessfultransactionsofdataandfor\nvalidatingdatainSqlServerDatabase\n•ValidatingtheCognosreportingobjectsinthereporteragainstthedesignspecificationdocument.","metadata":{"source":"/tmp/resume-processor-sLMqmq/Raju_N_DA.DOCX.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Copy of Raju_N_DA.DOCX","Producer":"Skia/PDF m122 Google Docs Renderer"},"metadata":null,"totalPages":8},"loc":{"pageNumber":3,"lines":{"from":31,"to":45}}}}],["b5ee9118-201e-4425-8127-f89457fd5a94",{"pageContent":"validatingdatainSqlServerDatabase\n•ValidatingtheCognosreportingobjectsinthereporteragainstthedesignspecificationdocument.\n•StrongKnowledgeinprotocolslikeSSHandSCPandtestedtheapplicationinUnixEnvironment\n•TestedthedimensionalcubesdevelopedbySQLServerAnalysisServices(SSAS)andqueried\nthedatausingSQLServerManagementstudio(SSMS)\n•DidDataModelingtestingforsourceidentification,datacollection,datatransformation,rule\nadministration,dataconsolidationanddatareconciliation.\n•Developedsqltoidentifythedeltasofdailyloads","metadata":{"source":"/tmp/resume-processor-sLMqmq/Raju_N_DA.DOCX.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Copy of Raju_N_DA.DOCX","Producer":"Skia/PDF m122 Google Docs Renderer"},"metadata":null,"totalPages":8},"loc":{"pageNumber":3,"lines":{"from":44,"to":51}}}}],["118044a3-1166-4f9a-b1b2-8ee3482c3e46",{"pageContent":"•IdentifyingfieldanddatadefectswithrequiredinformationinETLprocessinvariousmappings\nandonetoonemapping.\n•VerifiedalltheDataloadprocessesdevelopedforfetchingdatafromBigDatasystemtothe\nEnterpriseDatawarehouseusingSQLqueries.\n•PerformeddatavalidationontheflatfilesthatweregeneratedinUNIXandNetezzaenvironment\nusingUNIXandsqlLoadercommandsasnecessary\n•Defectsidentifiedintestingenvironmentwherecommunicatedtothedevelopersusingdefect\ntrackingtoolMercuryTest\n•Reportedthedefects/buginJiraticketsanddocumentedthereport.\n•Checkedthereportsforanynaminginconsistenciesandtoimproveuserreadability.\nEnvironment:AginityAmpPureAnalytics,NetezzaRelease7.2.1.1,Unix,Putty,Tivoli,Informatica,Confluence,Jira,\nAgile,IBMCognos10,IBMUnicaCampaign,HadoopHive,SqlServer,Oracle,Mobaxterm,Tableau\nIntuitTurbotax,Sandiego,CA(November2014–Sep2015)\nSr.BigDataAnalyst\n•Designed&CreatedMappingdocumentsbasedontheBusinessrequirements(Alsoreferred\nSourcetoTargetDetailedmappingdocument&Transformationrulesdocument).","metadata":{"source":"/tmp/resume-processor-sLMqmq/Raju_N_DA.DOCX.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Copy of Raju_N_DA.DOCX","Producer":"Skia/PDF m122 Google Docs Renderer"},"metadata":null,"totalPages":8},"loc":{"pageNumber":4,"lines":{"from":1,"to":16}}}}],["31b5ecaf-073e-4208-976c-85f4bcc42b4e",{"pageContent":"Sr.BigDataAnalyst\n•Designed&CreatedMappingdocumentsbasedontheBusinessrequirements(Alsoreferred\nSourcetoTargetDetailedmappingdocument&Transformationrulesdocument).\n•DevelopedapythonscripttogenerateTSVfilethatshowsnumberofcolumnsarenulland\nnumberofduplicaterecordsattablelevel\n•Developedpythonscriptstoexecutedatabasesqlqueriesandscheduledtheminjenkinsjobsto\nshow\nStatusoftestcase\n•Createdjenkinjobstorunscheduledpythonscriptsthathascomplexsqlqueriesfordata\nverification\n•DevelopedshellScripttoloadtextfilespresentinunixboxintocorrespondingdatabase\n•DevelopedtableaureportsaspertheOrganizationstandardsandtestedthem\n•Developedshellscriptincronjobtoreportdiskspaceusageofunixserver\n•DevelopedtableaureportstoensureavailabilityofdatainallthetableofverticatomeetUAT\nneeds\n•Developedshellscriptthatloadsintooracledatabasepresentinunixboxforreconcilingsource\ndata\n•Interactingwithseniorpeersorsubjectmatterexpertstolearnmoreabouttherequirements\n•InvolvedinthepreparationofTestStrategy&TestCases","metadata":{"source":"/tmp/resume-processor-sLMqmq/Raju_N_DA.DOCX.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Copy of Raju_N_DA.DOCX","Producer":"Skia/PDF m122 Google Docs Renderer"},"metadata":null,"totalPages":8},"loc":{"pageNumber":4,"lines":{"from":14,"to":32}}}}],["0e10f284-9ea4-4630-a82b-33ce04a1fef7",{"pageContent":"data\n•Interactingwithseniorpeersorsubjectmatterexpertstolearnmoreabouttherequirements\n•InvolvedinthepreparationofTestStrategy&TestCases\n•ActivelyinvolvedinFunctionalTesting,RegressionTesting.\n•DevelopedandPerformedexecutionofTestScriptstoshowhowmanyrecordsarepassedorfail\n•TransformeddatafromvariousdatasourceslikeNetezza,DB2,Oracle,flatfilesusingOLEDB\nconnectionbycreatingvariousSSISpackages\n•CreatedETLtestdataforallETLmappingrulestotestthefunctionalitydata\n•DevelopedcomplexSQLscriptsusinginnerjoinsandouterjoinsandsubqueries\n•CreateTestscriptsbyusingT-SQL.Programmingelementsincludecontrol-of-flowtechniques,\nlocalandglobalvariables,functions,anderrorhandlingtechniques\n•Participatedinthereleasecontrolprocess(whentheapplicationistransferredfromthebuildteam\ntothetestteam)toensurethatsolutionsmeetbusinessrequirements\n•ExtensivelyexecutedT-SQLqueriesinordertoviewsuccessfultransactionsofdataandfor\nvalidatingdatainSqlServerDatabas","metadata":{"source":"/tmp/resume-processor-sLMqmq/Raju_N_DA.DOCX.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Copy of Raju_N_DA.DOCX","Producer":"Skia/PDF m122 Google Docs Renderer"},"metadata":null,"totalPages":8},"loc":{"pageNumber":4,"lines":{"from":30,"to":44}}}}],["c699b2bc-33e9-48ea-8d1b-25acb0d8bd37",{"pageContent":"tothetestteam)toensurethatsolutionsmeetbusinessrequirements\n•ExtensivelyexecutedT-SQLqueriesinordertoviewsuccessfultransactionsofdataandfor\nvalidatingdatainSqlServerDatabas\n•UsedSplunkAnalyticsforreportingonexternaldatasetslocatedinHadoop \n•StrongKnowledgeinprotocolslikeSSHandSCPandtestedtheapplicationinUnixEnviroment\n•UsedSqooptotransferdatafromoracleintoHadoopHDFSaswellexportingdatafromHadoop\nHDFSfiletoRDBMS\n•TestedthedimensionalcubesdevelopedbySQLServerAnalysisServices(SSAS)andqueried\nthedatausingSQLServerManagementstudio(SSMS)","metadata":{"source":"/tmp/resume-processor-sLMqmq/Raju_N_DA.DOCX.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Copy of Raju_N_DA.DOCX","Producer":"Skia/PDF m122 Google Docs Renderer"},"metadata":null,"totalPages":8},"loc":{"pageNumber":4,"lines":{"from":42,"to":50}}}}],["e8e77b52-d335-4e3e-b79c-21040323b252",{"pageContent":"•IdentifyingfieldanddatadefectswithrequiredinformationinETLprocessinvariousmappings\nandonetoonemapping.\n•TestedalltheETLprocessesdevelopedforfetchingdatafromHadoopHivesystemtothetarget\nDatawarehouseOracleusingcomplexSQLqueries.\n•PerformeddatavalidationontheflatfilesthatweregeneratedinUNIXandHadoopenvironment\nusingUNIXandHadoopfscommandsasnecessary\n• TestingHadoopHBaseprovisioningonVMwarevirtualizedplatform \n•TestedBeaconsthatgeneratedfromchormeatDataEnterpriseintegrationwithHadoop\n•Verifyingfillforwardmethodologyforrecordsthatarenotpartofdailyload\n•CreatedAdhocreportsfortestingnecessitiesagainstreportdatabase\n•Reportedthedefects/buginJiraticketsanddocumentedthereport.\n•WrittenTestCasesforETLtocompareSourceandTargetdatabasesystems.\nEnvironment:Agile,SQLServer2008R2,Guidwire,Talend,Netezza,Microstratgegy9.2,WinSCP,Oracle10g,\nFlatfiles,TOAD,SQLServerManagementstudio(SSMS),V-SQL,TFS,Jira,UNIX,SSH,UNIXShellScript","metadata":{"source":"/tmp/resume-processor-sLMqmq/Raju_N_DA.DOCX.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Copy of Raju_N_DA.DOCX","Producer":"Skia/PDF m122 Google Docs Renderer"},"metadata":null,"totalPages":8},"loc":{"pageNumber":5,"lines":{"from":1,"to":14}}}}],["39cd0a88-b71b-481c-b3de-4d74f75719c2",{"pageContent":"Environment:Agile,SQLServer2008R2,Guidwire,Talend,Netezza,Microstratgegy9.2,WinSCP,Oracle10g,\nFlatfiles,TOAD,SQLServerManagementstudio(SSMS),V-SQL,TFS,Jira,UNIX,SSH,UNIXShellScript\n,Python,Vertica,Netezza,Sqlserver,Oracle,SourceTree,GitHub,QuerySurge,Beackoning,Source\nTree,nformatica,Glitch,Hive,Tableau,Informatica,ApacheAnt,Mobaxterm,pyunit,AquaStudio,Beyond\nCompare,Winmerge,HadoopHive,Tidal,Cronjob,Jenkins,splunk\nEntertainmentPartners,Burbank,CA(April2013–October2014)\nSrBusinessDataAnalyst–Vista5\nVista5isanapplicationDevelopedbytheEntertainmentpartnerstomeetthecorporateproductionaccountingneedsat\nthedetaillevelforAllExpensesandBudgetsofJournalEntries,GeneralLedgers,TrialBalancesandPayrollNeeds\nCorporationunitspresentinEntertainmentIndustry.thisreuquirementisdevelopedtofoundoutthediscrapnciesforthe\nweeklyreconciliations,dataintegrity,datamigrationofthelogicalsetforthereportsfromETLdata\n•InvolvedinBusinessanalysisandrequirementsgathering.","metadata":{"source":"/tmp/resume-processor-sLMqmq/Raju_N_DA.DOCX.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Copy of Raju_N_DA.DOCX","Producer":"Skia/PDF m122 Google Docs Renderer"},"metadata":null,"totalPages":8},"loc":{"pageNumber":5,"lines":{"from":13,"to":24}}}}],["b6133777-f4cb-4186-a389-3870c0d183a1",{"pageContent":"weeklyreconciliations,dataintegrity,datamigrationofthelogicalsetforthereportsfromETLdata\n•InvolvedinBusinessanalysisandrequirementsgathering.\n•Tested/Foundthedefectsinuniversesandreports.UsedMinglefortrackingthedefects.\n•TestedalldatareportspublishedtoWebincludingdashboards,summarized,master-detailedand\nAPI’s.\n•Testedgraphsforextracting,cleansing,transforming,integrating,andloadingdatausingData\nStageETLTool.\n•WorkedwithBigDataandHadoopFileSystem\n•WorkedasETLTesterresponsiblefortherequirements/ETLAnalysis,ETLTestingand\ndesigningoftheflowandthelogicfortheDatawarehouseproject.\n•AnalyzeddatausingHadoopcomponentsHiveandPig\n•InvolvedwithDevelopersinloadingdatafromedgenodetoHDFSusingshellscripting.\nTestedthedatathatwasloadedontoHDFS.\n•ValidatedtheprocessofLoadandtransformlargesetsofstructured,semistructuredand\nunstructureddatausingHadoop/BigDataconcepts\n•ResponsibleforprovidingDiscrepanciesofDataReconciliationreportsaccordingtoclient’s\nrequirementusingMSAccess.","metadata":{"source":"/tmp/resume-processor-sLMqmq/Raju_N_DA.DOCX.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Copy of Raju_N_DA.DOCX","Producer":"Skia/PDF m122 Google Docs Renderer"},"metadata":null,"totalPages":8},"loc":{"pageNumber":5,"lines":{"from":23,"to":39}}}}],["b6bca05f-a147-4868-b125-73c5d5e800a0",{"pageContent":"unstructureddatausingHadoop/BigDataconcepts\n•ResponsibleforprovidingDiscrepanciesofDataReconciliationreportsaccordingtoclient’s\nrequirementusingMSAccess.\n•Performed dataanalysis and dataprofiling usingcomplex SQL onvarioussourcessystems\nincludingOracleand Teradata.\n•UsedPuttytoconnecttoUNIXusingSSHprotocol,InternetExplorerandforwebbased\ncomponent\n•CreatedETLTestingprocessandvalidatebusinessrulesandpoliciestodataandtransformation\nincludingalldatapipelinesonhadoopclusters,monitoringdataactivitiesinHDFS,HIVEetc.\n•CreatedandcustomizedtheSettings.xmlfileforthelocalandserverconfigurationbuilds\n•CreatedShort-cutjoins,aliasesandcontextstomaketheuniverseloopsfree.\n•AtestreportingenvironmentwasestablishedtocombineDistributionWorkManagementand\ninformationintoaconsolidatedplacetoallowcombinedreportstobegenerated.","metadata":{"source":"/tmp/resume-processor-sLMqmq/Raju_N_DA.DOCX.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Copy of Raju_N_DA.DOCX","Producer":"Skia/PDF m122 Google Docs Renderer"},"metadata":null,"totalPages":8},"loc":{"pageNumber":5,"lines":{"from":37,"to":49}}}}],["8b1e89e1-ef02-4d09-bd75-b283883468d7",{"pageContent":"•Deployed.earBuild’sontoQAServerfromJbossandMavenforValidationofReportsthrough\nPuttyandWinscp\n•Deleted/AddedPermissionfortheusersinSQLServertoaccessbuildcreatedlocallyandserver\nside\n•LocallyCreatedtheBuildMavenwithClearCaseVersionfortheUserstoaccessthereports\nFromthisBuildfordatavalidation\n•DevelopETLtestplansbasedonteststrategy.Createdandexecutedtestcasesandtestscripts\nbasedonteststrategyandtestplansbasedonETLMappingdocument.\n•Testedandworkedoncreatingopendocumentreportsforbusiness.\n•Usedvarious@Functionslike@Prompt(foruserdefinedqueries),@Where(Forcreating\nconditionalfilters),and@SelectfortestingBusinessReportswithvariousboundaryconditions.\n•PreparationoftechnicalspecificationsandSourcetoTargetmappings.\n•ExtensivelyusedSQLprogramminginbackendandfront-endfunctions,procedures,packagesto\nimplementbusinessrulesandsecurity\n•ExperiencedusingquerytoolsforSQlServertovalidatereportsandtroubleshootdataquality\nissues.","metadata":{"source":"/tmp/resume-processor-sLMqmq/Raju_N_DA.DOCX.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Copy of Raju_N_DA.DOCX","Producer":"Skia/PDF m122 Google Docs Renderer"},"metadata":null,"totalPages":8},"loc":{"pageNumber":6,"lines":{"from":1,"to":16}}}}],["71f0a350-caee-40d2-a176-abee21d03489",{"pageContent":"implementbusinessrulesandsecurity\n•ExperiencedusingquerytoolsforSQlServertovalidatereportsandtroubleshootdataquality\nissues.\n•SolidtestingexperienceinworkingwithSQLStoredProcedures,triggers,viewsandworkedwith\nperformancetuningofcomplexSQLqueriesforbetterperformanceandefficiency.\n•Validatedformatofthereportsandfeeds.\n•EffectivelycommunicateDataAnalysisandtestingactivitiesandfindingsinoralandwritten\nformats.\n•ExtracteddatafromvarioussourceslikeflatfilesandSQLServer.\n•Designingandcreationofcomplexmappingsusinginvolvingtransformationssuchasexpression,\njoiner,aggregator,lookup,updatestrategy,andfilter.\n•CreatedvariousPL/SQLstoredproceduresfordroppingandrecreatingindexesontargettables.\n•Workedonissueswithmigrationfromdevelopmenttotesting.\n•DeployedthebuildsandReportscorrespondingusingmvncommandsonlocalandservers\nmachines\n•RestoredDatabasesandcreatedbackupsintoSQlserverfrombackups\n•Verifiedmigrationfromdifferentdatabases(i.e.Teradata,Oracle,MySQL)toHadoop","metadata":{"source":"/tmp/resume-processor-sLMqmq/Raju_N_DA.DOCX.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Copy of Raju_N_DA.DOCX","Producer":"Skia/PDF m122 Google Docs Renderer"},"metadata":null,"totalPages":8},"loc":{"pageNumber":6,"lines":{"from":14,"to":30}}}}],["1c79f2c5-78ad-4ff0-868b-4850651dc30e",{"pageContent":"machines\n•RestoredDatabasesandcreatedbackupsintoSQlserverfrombackups\n•Verifiedmigrationfromdifferentdatabases(i.e.Teradata,Oracle,MySQL)toHadoop\nEnvironment:Mingle,Jboss,Maven,Putty,Winscp,ClearCase,DataStage,MSAccess,SqlServer2008R2,Data\nStage8.0.1,Agile/ScrumMethodologies,SAP,Eclipse,XMLFiles,MSExcel,,Erwin4.0,UnixSSH\nScripting,Bussinessobjects,Connx,Linux,BussinessObjects,Hadoop,HDSF\nBankofAmerica(Accenture),AgouraHills,CA(July2011–March2013)\nSystemsDataAnalyst\nResponsibilities:\n•AssistedincreatingfactanddimensiontableimplementationinStarSchemamodelbasedon\nrequirements.\n•Developtestplansbasedonteststrategy.Createdandexecutedtestcasesbasedonteststrategy\nandtestplansbasedonETLMappingdocument.\n•PreparationoftechnicalspecificationsandSourcetoTargetmappings.\n•ExtensivelyusedSQLprogramminginbackendandfront-endfunctions,procedures,packagesto\nimplementbusinessrulesandsecurity\n•WrittentestcasestotesttheapplicationmanuallyinQualityCenterandautomatedthemin\nStoredProceduresusingSSMS","metadata":{"source":"/tmp/resume-processor-sLMqmq/Raju_N_DA.DOCX.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Copy of Raju_N_DA.DOCX","Producer":"Skia/PDF m122 Google Docs Renderer"},"metadata":null,"totalPages":8},"loc":{"pageNumber":6,"lines":{"from":28,"to":45}}}}],["1e85282c-14b3-40c6-a0b2-21922330afd6",{"pageContent":"implementbusinessrulesandsecurity\n•WrittentestcasestotesttheapplicationmanuallyinQualityCenterandautomatedthemin\nStoredProceduresusingSSMS\n•ExperiencewithExcelReportsanddynamicdashboards,scorecardsandstructuredreportsfor\noperationsandhighermanagement.\n•Testedbothconditionalformattingandthresholdleveltestingforseveralreportsdevelopedin\nCognosandExcel.","metadata":{"source":"/tmp/resume-processor-sLMqmq/Raju_N_DA.DOCX.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Copy of Raju_N_DA.DOCX","Producer":"Skia/PDF m122 Google Docs Renderer"},"metadata":null,"totalPages":8},"loc":{"pageNumber":6,"lines":{"from":43,"to":49}}}}],["15e0ce84-14b7-45b3-a092-4c88c7220a6d",{"pageContent":"•Analysis offunctionaland non-functional categorizeddataelementsfordataprofiling\nandmappingfromsourcetotargetdataenvironment.Developedworkingdocumentstosupportfindingsand\nassignspecifictasks\n•Involvedwith data profiling formultiplesourcesandanswered complexbusinessquestionsby\nprovidingdatatobusinessusers.\n•WroteKornscriptsin UNIX and LINUX environmenttoverifytheremoteloadingprocess\nusingFsecure,Ssh,Rsh shellcommands\n•Tetsted.netCodeusedforthewebbasedreports\n•TestedSSISPackagesusedforDataExtraction,TransformationandLoading\n•UsedvariousSSIStaskssuchaasconditionalsplit,DerivedColumnonthedata\nretrieved,performedDataValidationChecksduringstagingandthenloadedthedata\n•PreparedseveraltestscenariosfortheworkflowoftheentireETLcycle\n•DevelopedanddocumenteddataMappings/Transformations,andSqLsessionsasperthebusiness\nrequirement.InvolvedinthedevelopmentMappingsandalsotunedthemforbetterperformance.\n•ExtensiveexperienceinwritingSQLandPL/SQLscriptstovalidatethedatabasesystemsandfor","metadata":{"source":"/tmp/resume-processor-sLMqmq/Raju_N_DA.DOCX.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Copy of Raju_N_DA.DOCX","Producer":"Skia/PDF m122 Google Docs Renderer"},"metadata":null,"totalPages":8},"loc":{"pageNumber":7,"lines":{"from":1,"to":15}}}}],["c3517cc8-6b4d-4f26-badb-335141f5be6b",{"pageContent":"requirement.InvolvedinthedevelopmentMappingsandalsotunedthemforbetterperformance.\n•ExtensiveexperienceinwritingSQLandPL/SQLscriptstovalidatethedatabasesystemsandfor\nbackenddatabasetesting.\n•PerformedFunctionalTestingandBack-endTestingusingthedatabasecomparableresults\nmanually.\n•Loadnewormodifieddataintoback-endOracleandSQLServerdatabases.\n•TestedScheduledSSISPackageswhichranwithSQLAgentwhichareconfiguredlinkedservers\nfordataaccessbetweennewandoldservers\n•CreatedTables,GraphsandListingsforUserReports\n•CoordinatedwithAgileteamsandimplementedallTestPlansinaccordancetoneedof\ndevelopmentprojects\n•DevelopedautomatedtestscriptsfrommanualtestcasesforRegressiontestingbasedonthe\nrequirementdocumentsusingQuickTestProfessional.\n•Defectsidentifiedintestingenvironmentwherecommunicatedtothedevelopersusingdefect\ntrackingtoolMercuryTestDirector.\n• TestingHadoop(Both1.Xand2.X)provisioningonVMwarevirtualizedplatform \n•Implement,Gather,andreportteamandprojectmetricswhichdemonstratebusinessvalueand","metadata":{"source":"/tmp/resume-processor-sLMqmq/Raju_N_DA.DOCX.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Copy of Raju_N_DA.DOCX","Producer":"Skia/PDF m122 Google Docs Renderer"},"metadata":null,"totalPages":8},"loc":{"pageNumber":7,"lines":{"from":14,"to":30}}}}],["8473047a-f6c1-464b-b5c3-10272ffadcbc",{"pageContent":"trackingtoolMercuryTestDirector.\n• TestingHadoop(Both1.Xand2.X)provisioningonVMwarevirtualizedplatform \n•Implement,Gather,andreportteamandprojectmetricswhichdemonstratebusinessvalueand\nshowingcontinousimprovementinanAgileenvironment.\n•Developedscripts,utilities,simulators,datasetsandotherprogrammatictesttoolsasrequired\nexecutingtestplans.\n•Effectivelycommunicatetestingactivitiesandfindingsinoralandwrittenformats.\n•ReportedbugsandtrackeddefectsusingQualityCenter11\n•ExtensivelyusedInformaticapowercenterforextraction,transformationandloadingprocess.\n•WorkedwithETLgroupforunderstatingmappingsfordimensionsandfacts.\n•ExtracteddatafromvarioussourceslikeOracle,flatfilesandSQLServer.\n•Workedonissueswithmigrationfromdevelopmenttotesting.\nEnvironment:SSIS,Siperian,HPQualityCenter11and9.2,Oracle10g,Erwin4.0,XML,XSLT,UNIX,Shell\nScripting,SOAPUI,WebServices,SQlServer2008,WSDL,AutomatedUITesting,SOATest5.5.2,SQL,PL/SQL,","metadata":{"source":"/tmp/resume-processor-sLMqmq/Raju_N_DA.DOCX.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Copy of Raju_N_DA.DOCX","Producer":"Skia/PDF m122 Google Docs Renderer"},"metadata":null,"totalPages":8},"loc":{"pageNumber":7,"lines":{"from":28,"to":41}}}}],["a447a665-68d4-42c1-b054-42fe9c01c6d0",{"pageContent":"Environment:SSIS,Siperian,HPQualityCenter11and9.2,Oracle10g,Erwin4.0,XML,XSLT,UNIX,Shell\nScripting,SOAPUI,WebServices,SQlServer2008,WSDL,AutomatedUITesting,SOATest5.5.2,SQL,PL/SQL,\nTOAD7.0,Cognos,MSExcel,Agile/ScrumMethodologies,PivotTables,MicrosoftVisualStudio2008,Mircrosfot\nSilverlight.\nPreviousExperiences\nMICROSOFT,REDMOND,WA\n♦\nDATAWAREHOUSEANALYST\n♦\nJAN-11–\nJUNE11","metadata":{"source":"/tmp/resume-processor-sLMqmq/Raju_N_DA.DOCX.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Copy of Raju_N_DA.DOCX","Producer":"Skia/PDF m122 Google Docs Renderer"},"metadata":null,"totalPages":8},"loc":{"pageNumber":7,"lines":{"from":40,"to":50}}}}],["583d7495-8c6b-4b45-b8fc-c6070d75c2ea",{"pageContent":"LIBERTYMUTUAL,Dover,NH\n♦\nProgrammerAnalyst\n♦\nJul-09–Dec\n10\nTechnicalSkills\nDataModelingTools.Erwin.\nETLToolsInformaticaPC/PWX,Spark,Hive,AWSGlue,\nDatabricks,Qubole,Datastage\nReportingToolsIBMUnica,Microstrategy,Tableau,Cognos\nDatabasesOracle,IBMDB2,MSSQLServer,MySQL,Postgres,\nRedshift,Vertica,Db2,Teradata,SQLServer2008/2010\nNoSQLDatabasesMongoDB,DynamoDB,Cassandra\nBusinessIntelligence.Tableau,MicroStrategy\nProgramLanguages.SQL,PL/SQL,Java,Python,ShellScripting\nAWSServicesEC2,S3,EMR,Glue,Lambda,Elasticsearch.\nCertifications\nAmazonWebService(AWS)CertifiedSolutionArchitectAssociate\nMicrosoftPL/SQLCertification\nEducation\nFairfax,VirginiaStratfordUniversityJan2007-Dec2008\nMaster’sinComputerEngineering,December2008.\nGraduateCoursework:SoftwareDevelopment,InternetTechnologiesandwebdevelopment,datanetworks,\nDataModeling,DatabaseSecurity,WebSitedevelopment,DataWarehousing,DataAnalytics,Advanced\nDatabasemanagement.\nHyderabad,IndiaJNTUJuly2002–May2006","metadata":{"source":"/tmp/resume-processor-sLMqmq/Raju_N_DA.DOCX.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Copy of Raju_N_DA.DOCX","Producer":"Skia/PDF m122 Google Docs Renderer"},"metadata":null,"totalPages":8},"loc":{"pageNumber":8,"lines":{"from":1,"to":27}}}}],["53e98719-cfb7-4407-a615-9eec7998cc8c",{"pageContent":"DataModeling,DatabaseSecurity,WebSitedevelopment,DataWarehousing,DataAnalytics,Advanced\nDatabasemanagement.\nHyderabad,IndiaJNTUJuly2002–May2006\nBachelor’sinComputerScienceandInformationTechnology,May2006.","metadata":{"source":"/tmp/resume-processor-sLMqmq/Raju_N_DA.DOCX.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Copy of Raju_N_DA.DOCX","Producer":"Skia/PDF m122 Google Docs Renderer"},"metadata":null,"totalPages":8},"loc":{"pageNumber":8,"lines":{"from":25,"to":28}}}}]],{"0":"229a6e42-2a3a-41bc-bd02-26f25eec13ac","1":"996da698-6316-4073-b2f3-37dc7b4bfcd5","2":"ddcaf3f4-dffb-4b3b-b343-acd42b4793c4","3":"6129c1f7-409a-46f2-b9aa-c72d59900bdd","4":"c1dd0b04-d0aa-43b3-a704-05b5f077dfcf","5":"6deaf8c7-bffe-4dde-a9a4-184a3c644739","6":"9c47c8d5-6fe6-4d35-8b61-ad8cdd61f4cb","7":"2a361f05-262f-4939-acc3-22bc09097583","8":"6db89950-ea08-4cc8-b381-6798caf59b6c","9":"bec1c0ff-ce4a-49f9-be37-babc7392ece9","10":"b5ee9118-201e-4425-8127-f89457fd5a94","11":"118044a3-1166-4f9a-b1b2-8ee3482c3e46","12":"31b5ecaf-073e-4208-976c-85f4bcc42b4e","13":"0e10f284-9ea4-4630-a82b-33ce04a1fef7","14":"c699b2bc-33e9-48ea-8d1b-25acb0d8bd37","15":"e8e77b52-d335-4e3e-b79c-21040323b252","16":"39cd0a88-b71b-481c-b3de-4d74f75719c2","17":"b6133777-f4cb-4186-a389-3870c0d183a1","18":"b6bca05f-a147-4868-b125-73c5d5e800a0","19":"8b1e89e1-ef02-4d09-bd75-b283883468d7","20":"71f0a350-caee-40d2-a176-abee21d03489","21":"1c79f2c5-78ad-4ff0-868b-4850651dc30e","22":"1e85282c-14b3-40c6-a0b2-21922330afd6","23":"15e0ce84-14b7-45b3-a092-4c88c7220a6d","24":"c3517cc8-6b4d-4f26-badb-335141f5be6b","25":"8473047a-f6c1-464b-b5c3-10272ffadcbc","26":"a447a665-68d4-42c1-b054-42fe9c01c6d0","27":"583d7495-8c6b-4b45-b8fc-c6070d75c2ea","28":"53e98719-cfb7-4407-a615-9eec7998cc8c"}]