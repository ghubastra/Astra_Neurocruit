[[["bb2d5391-f22f-4586-bb7d-0f56dda87272",{"pageContent":"PAGE 1 OF 4\nAparajith Manthanam\n470-529-5439\namanthanam@gmail.com\nBig Data | Data Engineering| Snowflake/Data Strategist |GCP/AWS Architect\nS U M M A R Y   O F   Q U A L I F I C A T I O N S\nHighly analytical, motivated, and results-driven professional with well-rounded experience in the IT field, \nfocusing on heading world-class initiatives in Data Engineering, Reporting, Strategic Data driven solutions\nTECHNICAL SUMMARY:\n▪\nEnterprise Snowflake Cloud/ Data warehouse Data and Solution Architect, Data Modeler and Developer \n▪\nOver 14 years of experience with a broad knowledge of the Data Warehouse and Business Intelligence. \n▪\nSenior level technical skills in developing and maintaining Data Warehouse (cloud and on-prem) solutions \nand design including infrastructure, subject area data strategies, data modeling, data mining, data quality, \nsystem source analysis, ETL (cloud and on-prem) development, processes and architecture, data","metadata":{"source":"/tmp/resume-processor-yvKtZL/snowflake_dev_gc_profile_Aparajith_Manthanam-DBT_90.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"Skia/PDF m116 Google Apps Renderer"},"metadata":null,"totalPages":4},"loc":{"pageNumber":1,"lines":{"from":1,"to":17}}}}],["a12bf94f-c500-44ac-8e5d-e41bba7c99e9",{"pageContent":"system source analysis, ETL (cloud and on-prem) development, processes and architecture, data \ngovernance (includes MDM), database utilities and advanced SQL processes. \n▪\nInvolved in configuring DBT yml files. (profile,yml project.yml files)\n▪\nExperienced in configuring pre-hook, post-hook operators, snapshots in DBT\n▪\nExperience in Dimensional Data Modeling, Slowly Changing Dimensions Type I & II, Star Schema\n▪\nInvolved in legacy ETL migration to GCP Big Query. \n▪\nInvolved in integrating multiple legacy systems in the cloud.\n▪\nExperienced in Direct file loading for JSON and CSV type source file to Snowflake DB. \n▪\nExperienced in writing Python script for data extraction/ processing, Airflow DAGs and advanced SQL \nqueries.\n▪\nWell-versed with writing SNOW SQLs to perform data processing within Snowflake DB.\n▪\nProficient knowledge and hand on experience with advanced ETL and data processing pipelines\n▪","metadata":{"source":"/tmp/resume-processor-yvKtZL/snowflake_dev_gc_profile_Aparajith_Manthanam-DBT_90.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"Skia/PDF m116 Google Apps Renderer"},"metadata":null,"totalPages":4},"loc":{"pageNumber":1,"lines":{"from":17,"to":38}}}}],["352115b2-7113-4a14-8387-e3aeddef3c93",{"pageContent":"queries.\n▪\nWell-versed with writing SNOW SQLs to perform data processing within Snowflake DB.\n▪\nProficient knowledge and hand on experience with advanced ETL and data processing pipelines\n▪\nExcellent understanding on full software development life cycle (SLDC) of ETL process including \nrequirement analysis, design, development, support of testing and migration to production.\n▪\nExpertise in creating technical specification, High-level design, End-to-End design of data flow, Design \nReview, Code Review. Creating Test Plans and Documenting Test cases and Test results for large-scale \ndata warehouses. \n▪\nStrong understanding of data modeling concepts (logical & physical), including OLTP and OLAP (3NF, \nstar/snowflake schema, Data Vault) data structures for Enterprise Data Warehouses, Data Marts and \nOperational Data Stores and Designing next generation Business Intelligence solutions in data warehouse \nand decision support. \n▪","metadata":{"source":"/tmp/resume-processor-yvKtZL/snowflake_dev_gc_profile_Aparajith_Manthanam-DBT_90.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"Skia/PDF m116 Google Apps Renderer"},"metadata":null,"totalPages":4},"loc":{"pageNumber":1,"lines":{"from":33,"to":50}}}}],["c2a1d71b-6e9a-466a-9700-27654a1fe007",{"pageContent":"Operational Data Stores and Designing next generation Business Intelligence solutions in data warehouse \nand decision support. \n▪\nExperienced in solution architecture, end-to-end design of data flow, integration and consumption model of \nthe data. \n▪\nArchitect AWS environment in continuous data streams and batch processing/loading to host/deploy \nservices like Amazon S3, Amazon Redshift, SNS, SQS, AWS Lambda, ECS, EC2, AWS Glue\n▪\nTechnical Expertise in design, develop, Test, enhance, maintain and upgrade for  Snowflake cloud data \nwarehouse, Teradata, Informatica, Amazon Web Services, Python  Oracle, Autosys, Airflow orchestration, \n▪\nLead a team of 20 in Data migration from On-Premise Data warehouse Oracle to Google Cloud Platform \n▪\nProficient in creating ODI (Oracle Data Integrator) mappings to extract data from Teradata, SAP BW and \nfiles from S3 location to load in Oracle, Teradata, Snowflake DB and file.\n▪","metadata":{"source":"/tmp/resume-processor-yvKtZL/snowflake_dev_gc_profile_Aparajith_Manthanam-DBT_90.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"Skia/PDF m116 Google Apps Renderer"},"metadata":null,"totalPages":4},"loc":{"pageNumber":1,"lines":{"from":48,"to":64}}}}],["c8fc6c91-827c-4658-b862-22b1cb68dad0",{"pageContent":"▪\nProficient in creating ODI (Oracle Data Integrator) mappings to extract data from Teradata, SAP BW and \nfiles from S3 location to load in Oracle, Teradata, Snowflake DB and file.\n▪\nProcessing techniques including staging, reusability, data validation, change data Capture (CDC) using \nvarious ETL Tools and scripting.\nAdditional qualifications include:\nArmed with comprehensive knowledge of Business Intelligence, Big Data, Cloud  products, including \nemerging technologies AWS, Google Cloud, Tableau, ETL Snowflake NOSQL DBs, as well as of Agile \nmethodologies, along with Atlassian tools, such as JIRA and Confluence.","metadata":{"source":"/tmp/resume-processor-yvKtZL/snowflake_dev_gc_profile_Aparajith_Manthanam-DBT_90.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"Skia/PDF m116 Google Apps Renderer"},"metadata":null,"totalPages":4},"loc":{"pageNumber":1,"lines":{"from":61,"to":70}}}}],["37300dab-21fd-4325-b4cc-043836398a61",{"pageContent":"PAGE 2 OF 4\nStrong ability leveraging people, process, technology to build Software as a Service (SaaS) \napplications, retain high potential talent in all areas of organization and brand building.\nExpert in transforming strategic vision into tactical initiatives for any data driven organizations\nAn evangelist, A go-getter advocating the importance of using the right resources and technology to \nmaximum for successful delivery to stakeholder. \nSelf-starter, motivator and coach who combines business acumen, corporate culture, organizational \ngoals with the company’s talent pool to maximize their potential. \nRecognized as a Strong Team Influencer: effective in building synergy across engineering teams, non-\ntechnical teams, and business teams, building strategic partnership between teams and playing a key role in \ngenerating revenue, meeting business goals and minimizing the operational cost.\nP R O F E S S I O N A L   E X P E R I E N C E\nTYSON FOODS INC","metadata":{"source":"/tmp/resume-processor-yvKtZL/snowflake_dev_gc_profile_Aparajith_Manthanam-DBT_90.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"Skia/PDF m116 Google Apps Renderer"},"metadata":null,"totalPages":4},"loc":{"pageNumber":2,"lines":{"from":1,"to":13}}}}],["a6bf9cf7-a567-4749-a538-21b929d9ff1a",{"pageContent":"generating revenue, meeting business goals and minimizing the operational cost.\nP R O F E S S I O N A L   E X P E R I E N C E\nTYSON FOODS INC\nSenior Engineering Manager/Solution Architect \n  Feb 2021-till date\n▪\nInvolved in designing data modeling initiatives using Data governance tools\n▪\nInvolved in optimizing long running ETL DAGs\n▪\nExperienced in migrating legacy ETL solutions to Big query jobs\n▪\nExperienced in using snapshots, compiling/creating jobs in DBT\n▪\nCollibra implementation for entire Analytics/Insights organization\n▪\nCreated POC and implemented Snowflake data migration using Five tran.\n▪\nInvolved in writing DBT jobs, creating models in DBT and worked in integrating DBT with snowflake\n▪\nInvolved in writing SF queries in migrating on-prem SQLs to SF in DBT\n▪\nExperienced in implementing SF streams, tasks and setting up Airflow\n▪\nWorking closely with Snowflake support team for whitelisting azure subscriptions configuring connectors for \napps like service now. \n▪","metadata":{"source":"/tmp/resume-processor-yvKtZL/snowflake_dev_gc_profile_Aparajith_Manthanam-DBT_90.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"Skia/PDF m116 Google Apps Renderer"},"metadata":null,"totalPages":4},"loc":{"pageNumber":2,"lines":{"from":11,"to":37}}}}],["44ccec14-9a25-4a8e-9a80-c30d49d99c22",{"pageContent":"▪\nWorking closely with Snowflake support team for whitelisting azure subscriptions configuring connectors for \napps like service now. \n▪\nEfficient in working with international team across various time zones.\n▪\nExperienced in proposing MVP solutions and optimized solutions for many data warehousing/cloud projects.\n▪\nOpening new accounts in snowflake for different BU and enabling custom monitoring as per the requirements\n▪\nExpertise on fixing long running queries, handling large scale virtual warehouses, optimizing virtual \nwarehouses\nCognizant –\nWarner Media, Cummins Inc\n  \nData warehouse Solution Architect -Contractor July 2019 – Feb 2021\n\nBig data projects for AWS /GCP Cloud oriented portfolios from cognizant side.\n\nInvolved in  using IICS, AWS for Snowflake migration projects.\n\nManaged complete ETL migration project to Snowflake warehousing platform.\n\nInvolved in managing snowflake, AWS delivery for Warner media account.\n","metadata":{"source":"/tmp/resume-processor-yvKtZL/snowflake_dev_gc_profile_Aparajith_Manthanam-DBT_90.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"Skia/PDF m116 Google Apps Renderer"},"metadata":null,"totalPages":4},"loc":{"pageNumber":2,"lines":{"from":34,"to":58}}}}],["879f5e19-9732-43a2-9b34-2912786995e2",{"pageContent":"\nManaged complete ETL migration project to Snowflake warehousing platform.\n\nInvolved in managing snowflake, AWS delivery for Warner media account.\n\nExperienced in writing DAGs to extract data from source systems and load data into Snowflake\n\nExperienced in implementing ETL solutions into Snowflake\n\nInvolved in Snowflake Cost optimization, creating Virtual warehouses, \n\nInvolved in fixing long running queries, queries spilling to disk, optimizing virtual warehouses\n\nExperienced in snowflake credits usage, resource monitors\n\nInvolved in creating long running snowflake query as slack alerts, \n\nInvolved in generating daily/weekly/monthly reports for key performance indicators.\n\nEfficiently addressed and managed snowflake cost saving technical value proposition projects for various \nclients\n\nActed as a strong influencer between technical and non -technical teams\n\nOverseeing the co-ordination between technical/non-technical/business teams \n","metadata":{"source":"/tmp/resume-processor-yvKtZL/snowflake_dev_gc_profile_Aparajith_Manthanam-DBT_90.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"Skia/PDF m116 Google Apps Renderer"},"metadata":null,"totalPages":4},"loc":{"pageNumber":2,"lines":{"from":54,"to":79}}}}],["443ce97a-9ccc-421d-8846-87ab84b22ee0",{"pageContent":"clients\n\nActed as a strong influencer between technical and non -technical teams\n\nOverseeing the co-ordination between technical/non-technical/business teams \n\nImplemented Key initiatives which includes replacing legacy products across data related domains and \nincreased.","metadata":{"source":"/tmp/resume-processor-yvKtZL/snowflake_dev_gc_profile_Aparajith_Manthanam-DBT_90.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"Skia/PDF m116 Google Apps Renderer"},"metadata":null,"totalPages":4},"loc":{"pageNumber":2,"lines":{"from":74,"to":81}}}}],["05541abe-1552-46ca-b716-e6c9c6343517",{"pageContent":"PAGE 3 OF 4\n\nInfluencing teams and building synergy across QA,DEV,Support  teams \n\nWell versed in planning, execution, and implementation of any data related project\nMacy’s Inc. – Atlanta, GA \nData warehouse ArchitectJuly 2018–July 2019\n▪\nWorked with the Fulfillment Business Intelligence Team (FBIT) responsible for capturing and configuring the \noverall Macy’s store daily operational data into fully operational data warehouse, such as shipments, \nreservations, orders gathered and processed through the TIBCO and Oracle Data Integrator (ODI)\n▪\nImplemented the migration of entire Macy’s legacy ETL framework into Google Cloud Platform\n▪\nInfluenced multiple data integration teams in providing strategic solutions for data integration\n▪\nEffectively communicating with upstream, downstream application owners\n▪\nInvolved in effectively reducing the operational cost by $1mn\n▪\nOffered strategic roadmap for data migration projects and initiated ETL solutions in Google Cloud Platform \n(Big query)\n▪","metadata":{"source":"/tmp/resume-processor-yvKtZL/snowflake_dev_gc_profile_Aparajith_Manthanam-DBT_90.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"Skia/PDF m116 Google Apps Renderer"},"metadata":null,"totalPages":4},"loc":{"pageNumber":3,"lines":{"from":1,"to":23}}}}],["b4216ab0-c2d4-4be9-8968-e692f106b1c5",{"pageContent":"▪\nInvolved in effectively reducing the operational cost by $1mn\n▪\nOffered strategic roadmap for data migration projects and initiated ETL solutions in Google Cloud Platform \n(Big query)\n▪\nProactively participated in various initiatives and supported Architect teams which included the following:\nAdvanced Python and setting-up composer.\nSetting up GCP composer - Apache Airflow pipeline\nMigration of on-premise to cloud applications; and\nTuning GCP Big queries \nSunera Technologies /K12 Inc,Herndon -USA\nBusiness Intelligence ArchitectJan 2017-Dec 2017\n▪\nInitiated MDM project for School Staff Data Management (SSDM) integrating entire teacher information \nthroughout the K12 employees from multiple sources, such as flat files, web-services, and CSVs.\n▪\nGenerated high level documents to address the complex issues and to influence executive leadership teams.\n▪\nCreating presentations to influence senior management for key decision making. \n▪","metadata":{"source":"/tmp/resume-processor-yvKtZL/snowflake_dev_gc_profile_Aparajith_Manthanam-DBT_90.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"Skia/PDF m116 Google Apps Renderer"},"metadata":null,"totalPages":4},"loc":{"pageNumber":3,"lines":{"from":18,"to":38}}}}],["54d6a5d1-835c-4d05-8f34-7e13cb991e14",{"pageContent":"▪\nGenerated high level documents to address the complex issues and to influence executive leadership teams.\n▪\nCreating presentations to influence senior management for key decision making. \n▪\nIntroduced process improvements like automating job failures, self-healing processes for minimizing the \noperational cost.\n▪\nRendered active participation in issue discovery, managing offshore teams,hiring,coaching,mentoring \nindividuals improving Service levels.\n▪\nInvolved in complete SDLC includes planning, designing, implementation & delivery phases.\n▪\nCollaborating and communicating with external vendors, internal technical teams, senior leadership teams.\n▪\nExemplified expertise in managing  ETL framework.\n▪\nEvaluating big data products ,emerging technologies for new Big data Initiatives.\nIron Mountain ,Bangalore India\nTechnical Lead Feb 2014–Dec 2016\n▪\nHeld responsibility for the implementation of review and Data Governance processes, while providing \nadequate support to internal customers\n▪","metadata":{"source":"/tmp/resume-processor-yvKtZL/snowflake_dev_gc_profile_Aparajith_Manthanam-DBT_90.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"Skia/PDF m116 Google Apps Renderer"},"metadata":null,"totalPages":4},"loc":{"pageNumber":3,"lines":{"from":34,"to":57}}}}],["d3111d18-c165-4b31-9dd6-325192b5abcf",{"pageContent":"Technical Lead Feb 2014–Dec 2016\n▪\nHeld responsibility for the implementation of review and Data Governance processes, while providing \nadequate support to internal customers\n▪\nPlayed a vital role in improving the bond between business teams and technical teams\n▪\nPlayed a key role in managing the following major solution releases:\nRe-establishment of data load strategies;\nDeveloping new teams,Hiring,Coaching,Menoting individuals\nDriving new BI initiatives for internal sales, finance, pricing portfolio from scratch;\nInitiation of new data reconciliation strategies;\nSucceeded in enhancing data accuracy from 85 % to 99.8% as well as stabilizing billing data \nload for crucial finance applications\nA D D I T I O N A L   E X P E R I E N C E\nOracle ,Bangalore India\nMember Technical StaffSep 2011–Feb 2014\n▪\nHeld responsibility for the implementation of ODI,OBIEE,BIAPPS solutions while providing adequate support \nto internal Oracle Sales Consultants\n▪","metadata":{"source":"/tmp/resume-processor-yvKtZL/snowflake_dev_gc_profile_Aparajith_Manthanam-DBT_90.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"Skia/PDF m116 Google Apps Renderer"},"metadata":null,"totalPages":4},"loc":{"pageNumber":3,"lines":{"from":53,"to":73}}}}],["30d303ee-bd58-43c8-98b1-27b74e3fd04c",{"pageContent":"Member Technical StaffSep 2011–Feb 2014\n▪\nHeld responsibility for the implementation of ODI,OBIEE,BIAPPS solutions while providing adequate support \nto internal Oracle Sales Consultants\n▪\nActively interacting with internal teams, sales teams, QA teams\n▪\nPlayed a key role in managing the following major solution releases:","metadata":{"source":"/tmp/resume-processor-yvKtZL/snowflake_dev_gc_profile_Aparajith_Manthanam-DBT_90.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"Skia/PDF m116 Google Apps Renderer"},"metadata":null,"totalPages":4},"loc":{"pageNumber":3,"lines":{"from":69,"to":76}}}}],["945a8279-6a27-4582-80d2-f6a0423af22f",{"pageContent":"PAGE 4 OF 4\nCreating ODI,OBIEE,BIAPPS Platform\nInstalling, configuring Oracle Fusion middleware products for all beta releases\nInteracting with internal Oracle Sales consultants\nODI/OBIEE Lineage solutions\nInitiation of new data reconciliation strategies;\nAutomation of manual jobs through shell scripting;\nWipro, India\nSoftware DeveloperJan 2010–Sep 2011\n▪\nETL Developer primarily focused on developing ETL Solutions in Oracle Data Integrator\n▪\nResponsible for writing Teradata Fastload, Mload, BTEQ Scripts\n▪\nAddressing Data Loading issues in ODI\n▪\nImplementing new loading techniques for dimension tables\n▪\nData reconciliation for Landing, Staging,Warehouses\nDJ Info,India\nSoftware DeveloperMay 2008–Aug 2009\nE D U C A T I O N   A N D   C R E D E N T I A L S\nBachelor’s Degree in Information Technology, 2008\nANNA UNIVERSITY | INDIA\nT E C H N I C A L   A C U M E N\nBig Data Technologies:Apache Hadoop; Hadoop Clusters, MapR 5.5,Cloudera, Hadoop Common, Hadoop","metadata":{"source":"/tmp/resume-processor-yvKtZL/snowflake_dev_gc_profile_Aparajith_Manthanam-DBT_90.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"Skia/PDF m116 Google Apps Renderer"},"metadata":null,"totalPages":4},"loc":{"pageNumber":4,"lines":{"from":1,"to":26}}}}],["cafeca50-c47a-46a9-8885-194d3ee738d7",{"pageContent":"ANNA UNIVERSITY | INDIA\nT E C H N I C A L   A C U M E N\nBig Data Technologies:Apache Hadoop; Hadoop Clusters, MapR 5.5,Cloudera, Hadoop Common, Hadoop \nDistributed Google Cloud Platform, Replication; Cloudera Cluster;, Big Query,AWS \nRedshift, AWS Glue, EMR,AWS Athena, AWS Sage maker, Apache Airflow, Flume, \nRelational, hierarchical and graph databases, Python, Hive, distributed data file \nsystems, data federation and query optimization \nDatabases: Oracle 12c,11g/10g, DB2 8.0/7.0, MS-Server 2005, MYSQL5 + & Teradata\nData Modeling: Dimensional Data Modeling, Snow Flake Modeling, FACT and \nDimensions Tables, Physical and Logical Data Modeling, Erwin 3.5.2/3.x & Toad, \nSnowflake Databases\nLanguages:UNIX Shell Scripting, SQL, PL/SQL, Python\nETL/ Data integration Tools:ODI, Alteryx, Informatica,SSIS, & Data Stage , Oracle 12c, Redshift, Data \nProc,Alteryx, Looker, Alation, Oracle Golden gate,\nReporting tools: OBIEE, SAP Business Objects, Tableau, Operating Systems:","metadata":{"source":"/tmp/resume-processor-yvKtZL/snowflake_dev_gc_profile_Aparajith_Manthanam-DBT_90.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"Skia/PDF m116 Google Apps Renderer"},"metadata":null,"totalPages":4},"loc":{"pageNumber":4,"lines":{"from":24,"to":38}}}}],["c70fdf47-3a86-4da9-b83a-8f4e63973472",{"pageContent":"Proc,Alteryx, Looker, Alation, Oracle Golden gate,\nReporting tools: OBIEE, SAP Business Objects, Tableau, Operating Systems: \nWindows 2000, UNIX AIX.RHEL","metadata":{"source":"/tmp/resume-processor-yvKtZL/snowflake_dev_gc_profile_Aparajith_Manthanam-DBT_90.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"Skia/PDF m116 Google Apps Renderer"},"metadata":null,"totalPages":4},"loc":{"pageNumber":4,"lines":{"from":37,"to":39}}}}]],{"0":"bb2d5391-f22f-4586-bb7d-0f56dda87272","1":"a12bf94f-c500-44ac-8e5d-e41bba7c99e9","2":"352115b2-7113-4a14-8387-e3aeddef3c93","3":"c2a1d71b-6e9a-466a-9700-27654a1fe007","4":"c8fc6c91-827c-4658-b862-22b1cb68dad0","5":"37300dab-21fd-4325-b4cc-043836398a61","6":"a6bf9cf7-a567-4749-a538-21b929d9ff1a","7":"44ccec14-9a25-4a8e-9a80-c30d49d99c22","8":"879f5e19-9732-43a2-9b34-2912786995e2","9":"443ce97a-9ccc-421d-8846-87ab84b22ee0","10":"05541abe-1552-46ca-b716-e6c9c6343517","11":"b4216ab0-c2d4-4be9-8968-e692f106b1c5","12":"54d6a5d1-835c-4d05-8f34-7e13cb991e14","13":"d3111d18-c165-4b31-9dd6-325192b5abcf","14":"30d303ee-bd58-43c8-98b1-27b74e3fd04c","15":"945a8279-6a27-4582-80d2-f6a0423af22f","16":"cafeca50-c47a-46a9-8885-194d3ee738d7","17":"c70fdf47-3a86-4da9-b83a-8f4e63973472"}]